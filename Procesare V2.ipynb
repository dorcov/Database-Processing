{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data base processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-docx\n",
    "\n",
    "# !pip install openpyxl\n",
    "\n",
    "# !pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, Alignment\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.shared import RGBColor\n",
    "from docx.shared import Pt\n",
    "from docx.oxml import OxmlElement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectam fisierul\n",
    "file_name = input(\"Introduceti denumirea fisierului pentru procesare: \")\n",
    "file_name1 = f\"{file_name}.xlsx\"\n",
    "\n",
    "\n",
    "df_original = pd.read_excel(file_name1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectam datele originale si redenumim coloanele\n",
    "df_modified = df_original.copy()\n",
    "df_modified.rename(columns={'SbjNum': 'id', 'Srvyr': 'operator'}, inplace=True)\n",
    "\n",
    "# Doar pentru SUA\n",
    "#/////////////////////////////////////////////////////////////////////////////////\n",
    "# Replace values in the Q_3 column\n",
    "df_modified['cat'] = df_modified['cat'].replace({\n",
    "    'Vorbitori de limbă rusă cu vârsta 15-29 de ani.': 'Russian speakers 15-29 years.',\n",
    "    'Vorbitori de limbă rusă cu vârsta 30-39 de ani.': 'Russian speakers 30-39 years.',\n",
    "    'Vorbitori de limbă română cu vârsta 15-29 de ani': 'Romanian speakers 15-29 years.'\n",
    "})\n",
    "\n",
    "\n",
    "# Replace values in the Q_3 column\n",
    "df_modified['m'] = df_modified['m'].replace({\n",
    "    'Oraș': 'Urban',\n",
    "    'Sat': 'Rural'\n",
    "})\n",
    "#////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Stergem coloanele inutile\n",
    "columns_to_delete = ['Filter', 'Cancel', 'UsrUnq', 'Upload', 'SubjData', 'RvwTime', 'RvwComment', 'SrvyrComment',\n",
    "                    'Complete', 'Test', 'StopQ', 'ParentID', 'UTCDiff', 'QAScore', 'FrScName', 'ExReNum', 'VStart',\n",
    "                    'VEnd', 'RvwName', 'SbjNam']\n",
    "\n",
    "columns_to_delete = [col for col in columns_to_delete if col in df_modified.columns]\n",
    "df_modified.drop(columns=columns_to_delete, inplace=True, errors='ignore')\n",
    "\n",
    "# Trim all columns in the DataFrame\n",
    "df_modified = df_modified.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Stergem coloanele care au valori identice\n",
    "df_modified = df_modified.loc[:, df_modified.apply(pd.Series.nunique) != 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculăm statistica tuturor coloanelor\n",
    "summary_stats = df_original.describe()\n",
    "\n",
    "# Identificăm potențialele coloane care conțin vârsta respondentilor în funcție de datele statistice ale datelor\n",
    "potential_age_columns = []\n",
    "\n",
    "for col in summary_stats.columns:\n",
    "    # Verificăm dacă media și deviația standard se află în intervalul definit\n",
    "    if 20 <= summary_stats.at['mean', col] <= 80 and 5 <= summary_stats.at['std', col] <= 20:\n",
    "     potential_age_columns.append(col)\n",
    "\n",
    "# Verificăm dacă există coloane potențiale pentru vârstă\n",
    "if potential_age_columns:\n",
    "    age_column = potential_age_columns[0]\n",
    "\n",
    "    # Verificăm dacă coloana identificată există deja în dataframe-ul modificat\n",
    "    if age_column in df_modified.columns:\n",
    "        # Definim intervalurile de vârstă\n",
    "        age_bins = [18, 29, 37, 47, 57, 66, float('inf')]\n",
    "        age_labels = ['18-29', '30-37', '38-47','48-57','58-66', '67+']\n",
    "\n",
    "        # Înlocuim coloana identificată cu coloana nou creată cu etichetele de vârstă\n",
    "        df_modified[age_column] = pd.cut(df_modified[age_column], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "        df_modified.rename(columns={age_column: 'v1'}, inplace=True)\n",
    "    else:\n",
    "        print(f\"Column {age_column} not found in df_modified.\")\n",
    "\n",
    "        # Definim intervalurile de vârstă în funcție de coloana identificată\n",
    "        # Definim intervalurile de vârstă\n",
    "        age_bins = [18, 29, 37, 47, 57, 66, float('inf')]\n",
    "        age_labels = ['18-29', '30-37', '38-47','48-57','58-66', '67+']\n",
    "\n",
    "        # Înlocuim datele lipsă din coloana identificată a 'vârstei' cu mediana valorilor\n",
    "        df_modified[age_column].fillna(df_modified[age_column].median(), inplace=True)\n",
    "\n",
    "        # Aplicăm etichetele de vârstă în funcție de valorile prestabilite\n",
    "        df_modified['v1'] = pd.cut(df_modified[age_column], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "else:\n",
    "    print(\"No potential age columns found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Population proportions\n",
    "# population_proportions = {\n",
    "#     ('v1', '18-29', 's', 'Bărbat'): 7.832863787,\n",
    "#     ('v1', '18-29', 's', 'Femeie'): 7.867712534,\n",
    "#     ('v1', '30-37', 's', 'Bărbat'): 7.919225872,\n",
    "#     ('v1', '30-37', 's', 'Femeie'): 8.121530954,\n",
    "#     ('v1', '38-47', 's', 'Bărbat'): 8.867385321,\n",
    "#     ('v1', '38-47', 's', 'Femeie'): 9.223521284,\n",
    "#     ('v1', '48-57', 's', 'Bărbat'): 7.792088727,\n",
    "#     ('v1', '48-57', 's', 'Femeie'): 8.517023714,\n",
    "#     ('v1', '58-66', 's', 'Bărbat'): 7.499369379,\n",
    "#     ('v1', '58-66', 's', 'Femeie'): 9.489901461,\n",
    "#     ('v1', '67+', 's', 'Bărbat'): 6.210016381,\n",
    "#     ('v1', '67+', 's', 'Femeie'): 10.65936059,\n",
    "#     ('reg', '1', 'm', 'Urban'): 8.723901517,\n",
    "#     ('reg', '1', 'm', 'Rural'): 17.34464925,\n",
    "#     ('reg', '2', 'm', 'Urban'): 5.087108494,\n",
    "#     ('reg', '2', 'm', 'Rural'): 21.82653781,\n",
    "#     ('reg', '3', 'm', 'Urban'): 27.17595166,\n",
    "#     ('reg', '3', 'm', 'Rural'): 2.408172077,\n",
    "#     ('reg', '4', 'm', 'Urban'): 3.376669407,\n",
    "#     ('reg', '4', 'm', 'Rural'): 9.572135693,\n",
    "#     ('reg', '5', 'm', 'Urban'): 1.846969537,\n",
    "#     ('reg', '5', 'm', 'Rural'): 2.637904558,\n",
    "#     # ('etnia', 'Moldovenească'): 72.43012346,\n",
    "#     ('etnia', 'Rusă'): 6,\n",
    "#     ('etnia', 'Ucraineană'): 6.21,\n",
    "#     # ('etnia', 'Română'): 8.069876543,\n",
    "#     ('etnia', 'Găgăuză'): 4,\n",
    "#     ('etnia', 'Bulgară'): 1.93,\n",
    "#     ('etnia', 'Alta, specificați'): 1.36,\n",
    "#     ('regstat', 'Anenii Noi'): 5.254821581,\n",
    "#     ('regstat', 'Bălți'): 4.953227638,\n",
    "#     ('regstat', 'Botanica'): 5.480617285,\n",
    "#     ('regstat', 'Buiucani'): 5.0735467,\n",
    "#     ('regstat', 'Cahul'): 5.0735467,\n",
    "#     ('regstat', 'Călărași'): 4.901030983,\n",
    "#     ('regstat', 'Căușeni'): 4.726086588,\n",
    "#     ('regstat', 'Centru'): 4.9495249,\n",
    "#     ('regstat', 'Cimișlia'): 4.9495249,\n",
    "#     ('regstat', 'Ciocana'): 5.374941572,\n",
    "#     ('regstat', 'Comrat'): 4.874196089,\n",
    "#     ('regstat', 'Edineț'): 4.860101798,\n",
    "#     ('regstat', 'Fălești'): 4.78134895,\n",
    "#     ('regstat', 'Florești'): 4.953824853,\n",
    "#     ('regstat', 'Hîncești'): 4.87383776,\n",
    "#     ('regstat', 'Orhei'): 4.884985787,\n",
    "#     ('regstat', 'Rîșcani-Chișinău'): 5.374941572,\n",
    "#     ('regstat', 'Rîșcani-Nord'): 4.880526576,\n",
    "#     ('regstat', 'Soroca'): 4.82004853,\n",
    "#     ('regstat', 'Ungheni'): 4.959319238\n",
    "# }\n",
    "\n",
    "# # Define the function to update weights for combined categories\n",
    "# def update_weights_for_combined_category(df, combined_categories, target_proportion, current_weights):\n",
    "#     # Combine counts for similar categories\n",
    "#     combined_sample_count = sum(df[category].value_counts(dropna=False).get(value, 0)\n",
    "#                                 for category, value in combined_categories)\n",
    "\n",
    "#     # Calculate combined sample proportion\n",
    "#     combined_sample_proportion = combined_sample_count / len(df)\n",
    "\n",
    "#     # Calculate adjustment factor for the combined category\n",
    "#     adjustment_factor = (target_proportion / combined_sample_proportion \n",
    "#                          if combined_sample_proportion > 0 else 1)\n",
    "\n",
    "#     # Apply the adjustment factor to the weights of the matching rows\n",
    "#     for category, value in combined_categories:\n",
    "#         current_weights = current_weights.where(df[category] != value, \n",
    "#                                                 current_weights * adjustment_factor)\n",
    "\n",
    "#     return current_weights\n",
    "\n",
    "# # Check if all required columns for sample proportions are present in the DataFrame\n",
    "# required_columns = set([key[0] for key in population_proportions.keys()])\n",
    "# missing_columns = required_columns - set(df_modified.columns)\n",
    "\n",
    "# if missing_columns:\n",
    "#     print(\"Warning: Missing required columns for weight calculation:\", missing_columns)\n",
    "# else:\n",
    "#     # Proceed with weight calculation\n",
    "\n",
    "#     # Initialize weights to 1 for each respondent\n",
    "#     df_modified['Weight'] = 1\n",
    "\n",
    "#     # Handle the combined category 'Moldovenească' and 'Română'\n",
    "#     combined_categories = [('etnia', 'Moldovenească'), ('etnia', 'Română')]\n",
    "#     target_combined_proportion = 80.5 / 100  # 80.5% as a decimal\n",
    "#     df_modified['Weight'] = update_weights_for_combined_category(\n",
    "#         df_modified,\n",
    "#         combined_categories,\n",
    "#         target_combined_proportion,\n",
    "#         df_modified['Weight']\n",
    "#     )\n",
    "\n",
    "#     # Iterate over each demographic characteristic (including regstat) and update weights\n",
    "#     for key_tuple, pop_prop in population_proportions.items():\n",
    "#         category, value = key_tuple[:2]  # Extract category and value\n",
    "#         df_modified['Weight'] = update_weights_for_combined_category(\n",
    "#             df_modified,\n",
    "#             [(category, value)],\n",
    "#             pop_prop / 100,  # Convert percentage to proportion\n",
    "#             df_modified['Weight']\n",
    "#         )\n",
    "\n",
    "#     # Normalize the weights after each step\n",
    "#     df_modified['Weight'] /= df_modified['Weight'].mean()\n",
    "\n",
    "#     # Apply the final capping rules\n",
    "#     df_modified['Weight'] = np.clip(df_modified['Weight'], 0.5, 2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Population proportions\n",
    "# population_proportions = {\n",
    "    # ('v1', '18-29', 's', 'Bărbat'): 7.832863787,\n",
    "    # ('v1', '18-29', 's', 'Femeie'): 7.867712534,\n",
    "    # ('v1', '30-37', 's', 'Bărbat'): 7.919225872,\n",
    "    # ('v1', '30-37', 's', 'Femeie'): 8.121530954,\n",
    "    # ('v1', '38-47', 's', 'Bărbat'): 8.867385321,\n",
    "    # ('v1', '38-47', 's', 'Femeie'): 9.223521284,\n",
    "    # ('v1', '48-57', 's', 'Bărbat'): 7.792088727,\n",
    "    # ('v1', '48-57', 's', 'Femeie'): 8.517023714,\n",
    "    # ('v1', '58-66', 's', 'Bărbat'): 7.499369379,\n",
    "    # ('v1', '58-66', 's', 'Femeie'): 9.489901461,\n",
    "    # ('v1', '67+', 's', 'Bărbat'): 6.210016381,\n",
    "    # ('v1', '67+', 's', 'Femeie'): 10.65936059,\n",
    "    # ('reg', '1', 'm', 'Urban'): 8.723901517,\n",
    "    # ('reg', '1', 'm', 'Rural'): 17.34464925,\n",
    "    # ('reg', '2', 'm', 'Urban'): 5.087108494,\n",
    "    # ('reg', '2', 'm', 'Rural'): 21.82653781,\n",
    "    # ('reg', '3', 'm', 'Urban'): 27.17595166,\n",
    "    # ('reg', '3', 'm', 'Rural'): 2.408172077,\n",
    "    # ('reg', '4', 'm', 'Urban'): 3.376669407,\n",
    "    # ('reg', '4', 'm', 'Rural'): 9.572135693,\n",
    "    # ('reg', '5', 'm', 'Urban'): 1.846969537,\n",
    "    # ('reg', '5', 'm', 'Rural'): 2.637904558,\n",
    "    # ('etnia', 'Moldovenească'): 72.43012346,\n",
    "    # ('etnia', 'Rusă'): 6,\n",
    "    # ('etnia', 'Ucraineană'): 6.21,\n",
    "    # ('etnia', 'Română'): 8.069876543,\n",
    "    # ('etnia', 'Găgăuză'): 4,\n",
    "    # ('etnia', 'Bulgară'): 1.93,\n",
    "    # ('etnia', 'Alta, specificați'): 1.36,\n",
    "#     ('regstat', 'Anenii Noi'): 5.254821581,\n",
    "#     ('regstat', 'Bălți'): 4.953227638,\n",
    "#     ('regstat', 'Botanica'): 5.480617285,\n",
    "#     ('regstat', 'Buiucani'): 5.0735467,\n",
    "#     ('regstat', 'Cahul'): 5.0735467,\n",
    "#     ('regstat', 'Călărași'): 4.901030983,\n",
    "#     ('regstat', 'Căușeni'): 4.726086588,\n",
    "#     ('regstat', 'Centru'): 4.9495249,\n",
    "#     ('regstat', 'Cimișlia'): 4.9495249,\n",
    "#     ('regstat', 'Ciocana'): 5.374941572,\n",
    "#     ('regstat', 'Comrat'): 4.874196089,\n",
    "#     ('regstat', 'Edineț'): 4.860101798,\n",
    "#     ('regstat', 'Fălești'): 4.78134895,\n",
    "#     ('regstat', 'Florești'): 4.953824853,\n",
    "#     ('regstat', 'Hîncești'): 4.87383776,\n",
    "#     ('regstat', 'Orhei'): 4.884985787,\n",
    "#     ('regstat', 'Rîșcani-Chișinău'): 5.374941572,\n",
    "#     ('regstat', 'Rîșcani-Nord'): 4.880526576,\n",
    "#     ('regstat', 'Soroca'): 4.82004853,\n",
    "#     ('regstat', 'Ungheni'): 4.959319238\n",
    "# }\n",
    "\n",
    "\n",
    "# # Initialize weights to 1 for each respondent\n",
    "# df_modified['Weight'] = 1\n",
    "\n",
    "# # Define a tolerance level for convergence\n",
    "# tolerance = 0.02\n",
    "\n",
    "# # Pre-calculate filter conditions for each category-value pair\n",
    "# filter_conditions = {}\n",
    "# for key_tuple, pop_prop in population_proportions.items():\n",
    "#     category_value_pairs = [(key_tuple[i], key_tuple[i+1]) for i in range(0, len(key_tuple), 2)]\n",
    "#     filter_condition = pd.Series([True] * len(df_modified))\n",
    "#     for category, value in category_value_pairs:\n",
    "#         filter_condition &= (df_modified[category] == value)\n",
    "#     filter_conditions[key_tuple] = filter_condition\n",
    "\n",
    "# # Iterate until convergence\n",
    "# converged = False\n",
    "# while not converged:\n",
    "#     converged = True\n",
    "#     total_sample_count = df_modified['Weight'].sum()\n",
    "\n",
    "#     for key_tuple, pop_prop in population_proportions.items():\n",
    "#         filter_condition = filter_conditions[key_tuple]\n",
    "\n",
    "#         # Calculate current sample proportion\n",
    "#         sample_count = df_modified[filter_condition]['Weight'].sum()\n",
    "#         sample_proportion = sample_count / total_sample_count\n",
    "\n",
    "#         # Check if the current sample proportion is within the tolerance of the population proportion\n",
    "#         if abs(sample_proportion - (pop_prop / 100)) > tolerance:\n",
    "#             converged = False\n",
    "#             adjustment_factor = (pop_prop / 100) / sample_proportion\n",
    "\n",
    "#             # Apply the adjustment factor to the weights of the matching rows\n",
    "#             df_modified.loc[filter_condition, 'Weight'] *= adjustment_factor\n",
    "\n",
    "# # Normalize the weights after convergence\n",
    "# df_modified['Weight'] /= df_modified['Weight'].mean()\n",
    "\n",
    "# # Apply the final capping rules\n",
    "# df_modified['Weight'] = np.clip(df_modified['Weight'], 0.5, 2.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Population proportions\n",
    "# population_proportions = {\n",
    "#     ('v1', '18-29', 's', 'Bărbat'): 7.832863787,\n",
    "#     ('v1', '18-29', 's', 'Femeie'): 7.867712534,\n",
    "#     ('v1', '30-37', 's', 'Bărbat'): 7.919225872,\n",
    "#     ('v1', '30-37', 's', 'Femeie'): 8.121530954,\n",
    "#     ('v1', '38-47', 's', 'Bărbat'): 8.867385321,\n",
    "#     ('v1', '38-47', 's', 'Femeie'): 9.223521284,\n",
    "#     ('v1', '48-57', 's', 'Bărbat'): 7.792088727,\n",
    "#     ('v1', '48-57', 's', 'Femeie'): 8.517023714,\n",
    "#     ('v1', '58-66', 's', 'Bărbat'): 7.499369379,\n",
    "#     ('v1', '58-66', 's', 'Femeie'): 9.489901461,\n",
    "#     ('v1', '67+', 's', 'Bărbat'): 6.210016381,\n",
    "#     ('v1', '67+', 's', 'Femeie'): 10.65936059,\n",
    "#     ('reg', '1', 'm', 'Urban'): 8.723901517,\n",
    "#     ('reg', '1', 'm', 'Rural'): 17.34464925,\n",
    "#     ('reg', '2', 'm', 'Urban'): 5.087108494,\n",
    "#     ('reg', '2', 'm', 'Rural'): 21.82653781,\n",
    "#     ('reg', '3', 'm', 'Urban'): 27.17595166,\n",
    "#     ('reg', '3', 'm', 'Rural'): 2.408172077,\n",
    "#     ('reg', '4', 'm', 'Urban'): 3.376669407,\n",
    "#     ('reg', '4', 'm', 'Rural'): 9.572135693,\n",
    "#     ('reg', '5', 'm', 'Urban'): 1.846969537,\n",
    "#     ('reg', '5', 'm', 'Rural'): 2.637904558,\n",
    "#     ('etnia', 'Moldovenească'): 72.43012346,\n",
    "#     ('etnia', 'Rusă'): 6,\n",
    "#     ('etnia', 'Ucraineană'): 6.21,\n",
    "#     ('etnia', 'Română'): 8.069876543,\n",
    "#     ('etnia', 'Găgăuză'): 4,\n",
    "#     ('etnia', 'Bulgară'): 1.93,\n",
    "#     ('etnia', 'Alta, specificați'): 1.36,\n",
    "#     ('regstat', 'Anenii Noi'): 5.254821581,\n",
    "#     ('regstat', 'Bălți'): 4.953227638,\n",
    "#     ('regstat', 'Botanica'): 5.480617285,\n",
    "#     ('regstat', 'Buiucani'): 5.0735467,\n",
    "#     ('regstat', 'Cahul'): 5.0735467,\n",
    "#     ('regstat', 'Călărași'): 4.901030983,\n",
    "#     ('regstat', 'Căușeni'): 4.726086588,\n",
    "#     ('regstat', 'Centru'): 4.9495249,\n",
    "#     ('regstat', 'Cimișlia'): 4.9495249,\n",
    "#     ('regstat', 'Ciocana'): 5.374941572,\n",
    "#     ('regstat', 'Comrat'): 4.874196089,\n",
    "#     ('regstat', 'Edineț'): 4.860101798,\n",
    "#     ('regstat', 'Fălești'): 4.78134895,\n",
    "#     ('regstat', 'Florești'): 4.953824853,\n",
    "#     ('regstat', 'Hîncești'): 4.87383776,\n",
    "#     ('regstat', 'Orhei'): 4.884985787,\n",
    "#     ('regstat', 'Rîșcani-Chișinău'): 5.374941572,\n",
    "#     ('regstat', 'Rîșcani-Nord'): 4.880526576,\n",
    "#     ('regstat', 'Soroca'): 4.82004853,\n",
    "#     ('regstat', 'Ungheni'): 4.959319238\n",
    "# }\n",
    "\n",
    "\n",
    "# # Convert population proportions to DataFrame for easier processing\n",
    "# pop_prop_df = pd.DataFrame([(k[0], k[1], k[2], k[3], v) for k, v in population_proportions.items()], \n",
    "#                            columns=['Category1', 'Category2', 'Category3', 'Category4', 'PopProp'])\n",
    "# # Initialize weights to 1 for each respondent\n",
    "# df_modified['Weight'] = 1\n",
    "\n",
    "# def adjust_weights(df, pop_prop_df, tolerance=0.09, max_iterations=1048, verbose=False):\n",
    "#     # Precompute filtered DataFrames for each category-value pair\n",
    "#     filtered_dfs = {}\n",
    "#     for _, row in pop_prop_df.iterrows():\n",
    "#         category, value = row['Category'], row['Value']\n",
    "#         filtered_dfs[(category, value)] = df[df[category] == value]\n",
    "\n",
    "#     current_iteration = 0\n",
    "#     converged = False\n",
    "\n",
    "#     while not converged and current_iteration < max_iterations:\n",
    "#         converged = True\n",
    "#         current_iteration += 1\n",
    "\n",
    "#         total_sample_count = df['Weight'].sum()\n",
    "\n",
    "#         for _, row in pop_prop_df.iterrows():\n",
    "#             category, value, pop_prop = row['Category'], row['Value'], row['PopProp']\n",
    "#             df_filtered = filtered_dfs[(category, value)]\n",
    "\n",
    "#             sample_count = df_filtered['Weight'].sum()\n",
    "#             sample_proportion = sample_count / total_sample_count if total_sample_count > 0 else 0\n",
    "\n",
    "#             if abs(sample_proportion - (pop_prop / 100)) > tolerance:\n",
    "#                 converged = False\n",
    "#                 adjustment_factor = (pop_prop / 100) / sample_proportion if sample_proportion > 0 else 1\n",
    "#                 df.loc[df[category] == value, 'Weight'] *= adjustment_factor\n",
    "\n",
    "#                 if verbose:\n",
    "#                     print(f\"Iteration {current_iteration}, Adjusting {category}-{value}: {adjustment_factor}\")\n",
    "\n",
    "#         if df['Weight'].sum() > 0:\n",
    "#             df['Weight'] /= df['Weight'].mean()\n",
    "\n",
    "#     df['Weight'] = np.clip(df['Weight'], 0.5, 2.0)\n",
    "\n",
    "#     if verbose:\n",
    "#         print(\"Convergence Status:\", \"Converged\" if converged else \"Not Converged\")\n",
    "#         print(\"Total Iterations:\", current_iteration)\n",
    "\n",
    "#     return df\n",
    "\n",
    "# # Now call the function with df_modified and pop_prop_df\n",
    "# df_adjusted = adjust_weights(df_modified, pop_prop_df, tolerance=0.02, max_iterations=1048, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_sample_proportions(df, pop_prop_df):\n",
    "#     total_weight = df['Weight'].sum()\n",
    "#     calculated_proportions = {}\n",
    "\n",
    "#     for _, row in pop_prop_df.iterrows():\n",
    "#         category, value = row['Category'], row['Value']\n",
    "#         # Sum the weights for the specific category-value pair\n",
    "#         sum_weights = df[df[category] == value]['Weight'].sum()\n",
    "\n",
    "#         # Calculate the proportion\n",
    "#         proportion = sum_weights / total_weight if total_weight > 0 else 0\n",
    "#         calculated_proportions[(category, value)] = proportion\n",
    "\n",
    "#     return calculated_proportions\n",
    "\n",
    "# # Assuming df_modified is your dataset after applying weights\n",
    "# calculated_proportions = calculate_sample_proportions(df_modified, pop_prop_df)\n",
    "\n",
    "# # Print calculated proportions\n",
    "# for category_value, proportion in calculated_proportions.items():\n",
    "#     print(f\"{category_value}: {proportion}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissagreagtion column sellection + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the name of the operator\n",
    "df_modified['operator'] = df_modified['operator'].str.replace('.', ' ').apply(lambda x: ' '.join(x.capitalize() for x in x.split()))\n",
    "\n",
    "# Interactive input for multiple additional column names\n",
    "input_columns = input(\"Enter the names of the columns for disaggregation separated by a comma (leave blank if none): \")\n",
    "\n",
    "# Process the input\n",
    "if input_columns.strip():\n",
    "    disaggregation_columns = [col.strip() for col in input_columns.split(',')]\n",
    "else:\n",
    "    disaggregation_columns = []  # No columns selected\n",
    "\n",
    "# List of columns to select (columns starting with \"Q_\" or \"T_\", disaggregation columns)\n",
    "selected_columns = [col for col in df_modified.columns if col.startswith((\"Q_\", \"T_\"))] + disaggregation_columns\n",
    "\n",
    "\n",
    "# # Perform replacement of -1 with 'Necunoscut' only in disaggregation columns\n",
    "# for col in disaggregation_columns:\n",
    "#     if col in df_modified.columns:\n",
    "#         df_modified[col] = df_modified[col].replace('-1', 'Necunoscut')\n",
    "\n",
    "\n",
    "# Add 'Weight' column to the list if it exists in the DataFrame\n",
    "if 'Weight' in df_modified.columns:\n",
    "    selected_columns.append('Weight')\n",
    "\n",
    "# Inlocuirea valorii -1 cu  None\n",
    "df_modified.replace('-1', None, inplace=True)\n",
    "\n",
    "# Create a new DataFrame with selected columns\n",
    "df_selected = df_modified[selected_columns]\n",
    "\n",
    "# coloane cu calcul special\n",
    "suplimentar_columns = ['Q_47_O1', 'Q_47_O2', 'Q_47_O3','Q_26_O1','Q_26_O2','Q_26_O3']  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformig  multiple columns to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns_list = []\n",
    "\n",
    "for col in df_selected.filter(regex=r'^Q_\\d+_O\\d+$').columns:\n",
    "    if col not in suplimentar_columns:\n",
    "        # Extract question_number and option_number\n",
    "        match = re.match(r'^Q_(\\d+)_O(\\d+)$', col)\n",
    "        if match:\n",
    "            question_number, option_number = map(int, match.groups())\n",
    "            new_column_name = f\"Q{question_number}_{option_number}\"\n",
    "\n",
    "            # Use pd.get_dummies directly on the string values\n",
    "            dummy_columns = pd.get_dummies(df_selected[col], prefix=new_column_name, dummy_na=False)\n",
    "            dummy_columns_list.append(dummy_columns)\n",
    "\n",
    "# Concatenate all dummy columns\n",
    "df_dummies = pd.concat(dummy_columns_list, axis=1)\n",
    "\n",
    "# Create a list of columns to add to df_dummies, initially just the disaggregation columns\n",
    "columns_to_add = disaggregation_columns\n",
    "\n",
    "# Add 'Weight' column to the list if it exists in df_selected\n",
    "if 'Weight' in df_selected.columns:\n",
    "    columns_to_add.append('Weight')\n",
    "\n",
    "# Add the selected columns to df_dummies\n",
    "df_dummies = pd.concat([df_dummies, df_selected[columns_to_add]], axis=1)\n",
    "\n",
    "\n",
    "# Concatenate df_dummies with df_modified\n",
    "df_modified = pd.concat([df_modified, df_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies calculations and weights aplicationv + special q_option questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_weighted_freq_table(df, response_column, disaggregation_columns, weight_column):\n",
    "    # Calculate 'N' as unweighted count of responses\n",
    "    basic_freq_table = df.groupby(response_column).size().rename('N').reset_index()\n",
    "\n",
    "    # Calculate weighted total for the 'Total' column\n",
    "    weighted_total = df.groupby(response_column)[weight_column].sum().rename('Weighted_Total').reset_index()\n",
    "    total_weight = weighted_total['Weighted_Total'].sum()\n",
    "    weighted_total['Total'] = (weighted_total['Weighted_Total'] / total_weight) * 100\n",
    "    weighted_total['Total'] = weighted_total['Total'].round(1)\n",
    "\n",
    "    # Merge the unweighted 'N' with the weighted 'Total'\n",
    "    merged_table = basic_freq_table.merge(weighted_total[[response_column, 'Total']], on=response_column)\n",
    "\n",
    "    pivot_tables = [merged_table.set_index(response_column)]\n",
    "    for disaggregation_column in disaggregation_columns:\n",
    "        # For disaggregated columns, use weighted sum\n",
    "        weighted_counts = df.groupby([response_column, disaggregation_column])[weight_column].sum().reset_index(name='Weighted_N')\n",
    "        pivot_table = weighted_counts.pivot(index=response_column, columns=disaggregation_column, values='Weighted_N').fillna(0)\n",
    "        pivot_tables.append(pivot_table)\n",
    "\n",
    "    return pd.concat(pivot_tables, axis=1).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "def create_unweighted_freq_table(df, response_column, disaggregation_columns):\n",
    "    # Function to create frequency table without weights (count)\n",
    "    basic_freq_table = df.groupby(response_column).size().rename('N').reset_index()\n",
    "    basic_freq_table['Total'] = (basic_freq_table['N'] / basic_freq_table['N'].sum()) * 100\n",
    "    basic_freq_table['Total'] = basic_freq_table['Total'].round(1)\n",
    "\n",
    "    pivot_tables = [basic_freq_table.set_index(response_column)]\n",
    "    for disaggregation_column in disaggregation_columns:\n",
    "        counts = df.groupby([response_column, disaggregation_column]).size().reset_index(name='N')\n",
    "        pivot_table = counts.pivot(index=response_column, columns=disaggregation_column, values='N').fillna(0)\n",
    "        pivot_tables.append(pivot_table)\n",
    "\n",
    "    return pd.concat(pivot_tables, axis=1).reset_index()\n",
    "\n",
    "\n",
    "apply_weights = 'n'  # Default to not applying weights\n",
    "\n",
    "# Check if 'Weight' column is present in the DataFrame\n",
    "if 'Weight' in df_modified.columns:\n",
    "    apply_weights = input(\"Apply weights? (y/n): \").strip().lower()\n",
    "   \n",
    "\n",
    "# Define regular expressions for each category\n",
    "q_digit_regex = re.compile(r'^Q_\\d+$')\n",
    "t_q_regex = re.compile(r'^T_Q_\\d+_\\d+$')\n",
    "\n",
    "# Filter columns based on regular expressions\n",
    "q_digit_columns = [col for col in df_selected.columns if q_digit_regex.match(col)]\n",
    "t_q_columns = [col for col in df_selected.columns if t_q_regex.match(col)]\n",
    "\n",
    "\n",
    "\n",
    "# Extend the q_digit_columns list with additional columns\n",
    "q_digit_columns.extend(suplimentar_columns)\n",
    "\n",
    "# Create frequency tables based on user choice\n",
    "all_separated_tables = {}\n",
    "for question_column in q_digit_columns + t_q_columns:\n",
    "    # Ensure 'Weight' is not treated as a disaggregation column\n",
    "    disaggregation_columns_excluding_weight = [col for col in disaggregation_columns if col != 'Weight']\n",
    "\n",
    "    if apply_weights == 'y':\n",
    "        separated_table = create_weighted_freq_table(df_selected, question_column, disaggregation_columns_excluding_weight, 'Weight')\n",
    "    else:\n",
    "        separated_table = create_unweighted_freq_table(df_selected, question_column, disaggregation_columns_excluding_weight)\n",
    "    all_separated_tables[question_column] = separated_table\n",
    "\n",
    "# Export frequency tables to Excel in separate sheets\n",
    "with pd.ExcelWriter('frequency_tables.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Export q_digit_tables to one sheet\n",
    "    startrow_q_digit = 1\n",
    "    for question_column in q_digit_columns:\n",
    "        table = all_separated_tables[question_column]\n",
    "        if isinstance(table.columns, pd.MultiIndex):\n",
    "            table.columns = ['_'.join(map(str, col_tuple)) for col_tuple in table.columns.values]\n",
    "        table.to_excel(writer, sheet_name='Q_digit_Tables', index=False, startrow=startrow_q_digit)\n",
    "        startrow_q_digit += len(table) + 3  # Adjust the start row for the next table\n",
    "\n",
    "    # Export t_q_tables to another sheet\n",
    "    startrow_t_q = 1\n",
    "    for question_column in t_q_columns:\n",
    "        table = all_separated_tables[question_column]\n",
    "        if isinstance(table.columns, pd.MultiIndex):\n",
    "            table.columns = ['_'.join(map(str, col_tuple)) for col_tuple in table.columns.values]\n",
    "        table.to_excel(writer, sheet_name='T_Q_Tables', index=False, startrow=startrow_t_q)\n",
    "        startrow_t_q += len(table) + 3  # Adjust the start row for the next table\n",
    "\n",
    "    # Add additional code for df_dummies if needed\n",
    "\n",
    "    df_dummies.to_excel(writer, sheet_name='dummies_+variabila', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectam fisierul\n",
    "filename = input(\"Introduceti denumirea fisierului care contine textul intrebarilor: \")\n",
    "filename1 = f\"{filename}.xls\"\n",
    "\n",
    "df_questions = pd.read_excel(filename1)\n",
    "\n",
    "# Method 1: Using loc\n",
    "questions_df_filtered = df_questions.loc[df_questions['Is Topic'] != False]\n",
    "# Dropping the first two rows of questions_df_filtered\n",
    "questions_df_filtered = questions_df_filtered.iloc[2:]\n",
    "# Dropping rows where 'Question Index' column has NA/null values\n",
    "questions_df_filtered = questions_df_filtered.dropna(subset=['Question Index'])\n",
    "# Selecting only 'Question Index' and 'Text' columns\n",
    "questions_df_filtered = questions_df_filtered[['Question Index', 'Text']]\n",
    "# Replacing <b> and </b> with an empty string in the 'Text' column\n",
    "questions_df_filtered['Text'] = questions_df_filtered['Text'].replace('<b>|</b>', '', regex=True)\n",
    "# Extracting column names that start with \"Q\" and \"T_Q\"\n",
    "filtered_columns = [col for col in df_original.columns if col.startswith('Q_') or col.startswith('T_Q')]\n",
    "\n",
    "# Creating a new DataFrame with these column names as values in a single column\n",
    "df_columns = pd.DataFrame({'column_names': filtered_columns})\n",
    "\n",
    "# Create a new DataFrame for modified data with T_Q_digit part as the header of each section\n",
    "df_columns_new = pd.DataFrame(columns=df_columns.columns)\n",
    "\n",
    "# Initialize last_group as None to indicate no group has been encountered yet\n",
    "last_group = None\n",
    "\n",
    "for index, row in df_columns.iterrows():\n",
    "    # Extract the group number from the 'T_Q' pattern\n",
    "    match = re.match(r'T_Q_(\\d+)_\\d+', str(row['column_names']))\n",
    "    if match:\n",
    "        current_group = int(match.group(1))\n",
    "\n",
    "        # Insert a row with the T_Q_digit part if it's the first group or if the group number changes\n",
    "        if last_group is None or current_group != last_group:\n",
    "            df_columns_new = df_columns_new.append(pd.Series({'column_names': f'T_Q_{current_group}'}), ignore_index=True)\n",
    "\n",
    "        # Update the last seen group number\n",
    "        last_group = current_group\n",
    "\n",
    "    # Append the current row\n",
    "    df_columns_new = df_columns_new.append(row)\n",
    "\n",
    "# Reset index for the new DataFrame\n",
    "df_columns_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def filter_specific_pattern(dataframe, pattern_to_keep, general_pattern):\n",
    "    # Function to check if the entry matches the general pattern and ends with the specific pattern\n",
    "    def entry_matches(entry):\n",
    "        return re.match(general_pattern, entry) and entry.endswith(pattern_to_keep)\n",
    "\n",
    "    # Apply the filter to the DataFrame\n",
    "    filtered_dataframe = dataframe[\n",
    "        dataframe['column_names'].apply(lambda x: not re.match(general_pattern, x) or entry_matches(x))\n",
    "    ]\n",
    "\n",
    "    return filtered_dataframe\n",
    "\n",
    "# The specific pattern we want to keep\n",
    "specific_ending = '_O1'\n",
    "\n",
    "# The general pattern that the questions must match (e.g., 'Q_number_Osomething')\n",
    "question_pattern = r'Q_\\d+_O\\d+'\n",
    "\n",
    "# Apply the filter function to the DataFrame\n",
    "df_columns_new = filter_specific_pattern(df_columns_new, specific_ending, question_pattern)\n",
    "\n",
    "# Step 1: Remove '_O1' from the end of strings in 'column_names'\n",
    "df_columns_new['column_names'] = df_columns_new['column_names'].str.replace('_O1', '', regex=False)\n",
    "\n",
    "# Step 2: Drop rows where 'column_names' ends with 'S'\n",
    "df_columns_new = df_columns_new[~df_columns_new['column_names'].str.endswith('S')]\n",
    "\n",
    "# Truncate questions_df_filtered to match the length of df_columns_new\n",
    "questions_df_filtered = questions_df_filtered.iloc[:len(df_columns_new)]\n",
    "\n",
    "# Assign values from 'column_names' in df_columns_new to 'q_index' in questions_df_filtered\n",
    "questions_df_filtered['q_index'] = df_columns_new['column_names'].values\n",
    "\n",
    "# Reorder columns and drop 'Question index'\n",
    "questions_df_filtered = questions_df_filtered[['q_index', 'Text']].copy()\n",
    "\n",
    "questions_filtered_df = questions_df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_and_rename(df, disaggregation_columns, weight_column='Weight', apply_weights='n'):\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    # Check if weight column is present and user chose to apply weights\n",
    "    weight_present = weight_column in df.columns and apply_weights == 'y'\n",
    "\n",
    "    for column in disaggregation_columns:\n",
    "        if column in df.columns:\n",
    "            result_df[column] = df[column]\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column.startswith('Q') and column.count('_') == 2:\n",
    "            if weight_present:\n",
    "                weighted_column = df[column] * df[weight_column]\n",
    "            else:\n",
    "                weighted_column = df[column]\n",
    "\n",
    "            question, option, response = column.split('_')\n",
    "            result_column = f'{question}_{response}'\n",
    "\n",
    "            if result_column in result_df.columns:\n",
    "                result_df[result_column] += weighted_column\n",
    "            else:\n",
    "                new_df = pd.DataFrame({result_column: weighted_column})\n",
    "                result_df = pd.concat([result_df, new_df], axis=1)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Usage of the function\n",
    "result_df = sum_and_rename(df_dummies.copy(), disaggregation_columns, 'Weight', apply_weights)\n",
    "\n",
    "# Step 1: Extract Question and Response\n",
    "question_response_data = []\n",
    "for column in result_df.columns:\n",
    "    if column.startswith('Q'):\n",
    "        question, response = column.split('_', 1)\n",
    "        question_response_data.append({\n",
    "            'q': question,\n",
    "            'Răspunsuri': response,\n",
    "            'Column': column\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "question_response_df = pd.DataFrame(question_response_data)\n",
    "\n",
    "\n",
    "# Determine if weights should be applied\n",
    "weight_present = 'Weight' in df_dummies.columns and apply_weights == 'y'\n",
    "\n",
    "# Step 2 and 3: Calculate Absolute and Relative Frequency\n",
    "frequency_data = []\n",
    "for _, row in question_response_df.iterrows():\n",
    "    column = row['Column']\n",
    "\n",
    "    # Calculate absolute frequency as a count of non-zero responses (unweighted)\n",
    "    abs_frequency = (result_df[column] != 0).sum()\n",
    "\n",
    "    # Calculate the total responses for the question (considering multiple selections)\n",
    "    if weight_present:\n",
    "        # Use the weighted sum for the total responses across all options for the question\n",
    "        total_responses = result_df[[col for col in result_df.columns if col.startswith(row['q'])]].multiply(result_df['Weight'], axis=0).sum().sum()\n",
    "    else:\n",
    "        # Use the sum of all responses for all options within the question (unweighted)\n",
    "        total_responses = result_df[[col for col in result_df.columns if col.startswith(row['q'])]].sum().sum()\n",
    "\n",
    "    # Calculate relative frequency considering multiple selections\n",
    "    if weight_present:\n",
    "        rel_frequency = (result_df[column].multiply(result_df['Weight']).sum() / total_responses * 100) if total_responses != 0 else 0\n",
    "    else:\n",
    "        # For the unweighted scenario, calculate the relative frequency normally\n",
    "        rel_frequency = (result_df[column].sum() / total_responses * 100) if total_responses != 0 else 0\n",
    "\n",
    "    frequency_data.append({\n",
    "        'q': row['q'],\n",
    "        'Răspunsuri': row['Răspunsuri'],\n",
    "        'N': abs_frequency,  # Unweighted count of responses\n",
    "        'Total': rel_frequency  # Weighted or unweighted percentage\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "frequency_df = pd.DataFrame(frequency_data)\n",
    "\n",
    "# Step 4: Calculate Relative Frequencies for Disaggregation Categories\n",
    "disaggregation_columns = [col for col in disaggregation_columns if col != 'Weight']\n",
    "for col in disaggregation_columns:\n",
    "    for category in result_df[col].unique():\n",
    "        category_filter = result_df[col] == category\n",
    "        category_count = result_df[category_filter].shape[0]  # Count of entries in the category\n",
    "\n",
    "        for _, row in question_response_df.iterrows():\n",
    "            question_col = row['Column']\n",
    "\n",
    "            # Calculate absolute frequency for the category\n",
    "            abs_frequency = result_df[category_filter][question_col].sum()\n",
    "\n",
    "            # Calculate and store relative frequency\n",
    "            rel_frequency = (abs_frequency / category_count * 100) if category_count != 0 else 0\n",
    "            frequency_df.loc[(frequency_df['q'] == row['q']) & (frequency_df['Răspunsuri'] == row['Răspunsuri']), f'{category}'] = rel_frequency\n",
    "\n",
    "# Step 5: Assemble the Frequency Table\n",
    "frequency_df = frequency_df.round(1)  # Round the frequencies for better readability\n",
    "\n",
    "\n",
    "# Sorting values within each 'q' group based on the 'N' column in descending order\n",
    "frequency_df = frequency_df.groupby('q', group_keys=False).apply(lambda x: x.sort_values('N', ascending=False))\n",
    "\n",
    "# Resetting the index after sorting\n",
    "frequency_df = frequency_df.reset_index(drop=True)\n",
    "\n",
    "results_multiple = frequency_df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency tables processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = pd.read_excel('frequency_tables.xlsx', sheet_name='Q_digit_Tables')\n",
    "df_t = pd.read_excel('frequency_tables.xlsx', sheet_name='T_Q_Tables')\n",
    "\n",
    "\n",
    "# Assuming df_q is your DataFrame\n",
    "new_column_names = ['Răspunsuri'] + list(df_q.iloc[0, 1:])\n",
    "df_q.columns = new_column_names\n",
    "new_column_names = ['Răspunsuri'] + list(df_t.iloc[0, 1:])\n",
    "df_t.columns = new_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q_digit Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POCESAREA INTREBARILOR IN FORMAT Q_DIGIT\n",
    "\n",
    "#//////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Assuming df_q is your DataFrame\n",
    "\n",
    "# Drop rows where 'question' is NaN\n",
    "df_q = df_q.dropna(subset=['Răspunsuri'])\n",
    "\n",
    "# Calculul frecventelor relative pentru coloanele dezagregate\n",
    "\n",
    "# Identify the rows where a new question starts\n",
    "question_indices = df_q[df_q['Răspunsuri'].str.startswith('Q_')].index\n",
    "\n",
    "# Iterate through each question section\n",
    "for i in range(len(question_indices) - 1):\n",
    "    start_idx = question_indices[i]\n",
    "    end_idx = question_indices[i + 1]\n",
    "\n",
    "    # Extract the relevant section of the DataFrame\n",
    "    section = df_q.loc[start_idx+1:end_idx]\n",
    "\n",
    "    # Convert columns to numeric (excluding the first 3 columns)\n",
    "    section.iloc[:, 3:] = section.iloc[:, 3:].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Calculate the sum of each column in the section (excluding the first 3 columns)\n",
    "    col_sums = section.iloc[:, 3:].sum(axis=0)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    col_sums_nonzero = col_sums.replace(0, 1)  # Replace zeros with 1 to avoid division by zero\n",
    "    section.iloc[:, 3:] = section.iloc[:, 3:].div(col_sums_nonzero, axis=1) * 100\n",
    "\n",
    "    # Replace NaN values with 0 after division\n",
    "    section.iloc[:, 3:].fillna(0, inplace=True)\n",
    "\n",
    "    # Update the original DataFrame with the calculated values\n",
    "    df_q.loc[start_idx+1:end_idx] = section\n",
    "\n",
    "# Process the last section separately\n",
    "start_idx = question_indices[-1]\n",
    "section = df_q.loc[start_idx+1:]\n",
    "\n",
    "# Repeat the normalization steps for the last section\n",
    "section.iloc[:, 3:] = section.iloc[:, 3:].apply(pd.to_numeric, errors='coerce')\n",
    "col_sums = section.iloc[:, 3:].sum(axis=0)\n",
    "col_sums_nonzero = col_sums.replace(0, 1)\n",
    "section.iloc[:, 3:] = section.iloc[:, 3:].div(col_sums_nonzero, axis=1) * 100\n",
    "section.iloc[:, 3:].fillna(0, inplace=True)\n",
    "df_q.loc[start_idx+1:] = section\n",
    "\n",
    "\n",
    "\n",
    "# Assuming df_q is your DataFrame\n",
    "# Find the index of the \"Relative Frequency\" column\n",
    "relative_frequency_index = df_q.columns.get_loc(\"Total\")\n",
    "\n",
    "# Select columns after the \"Relative Frequency\" column\n",
    "columns_to_round = df_q.columns[relative_frequency_index + 1:]\n",
    "\n",
    "# Iterate through the columns, convert to numeric, and round\n",
    "for column in columns_to_round:\n",
    "    # Try to convert the column to numeric\n",
    "    df_q[column] = pd.to_numeric(df_q[column], errors='coerce')\n",
    "\n",
    "    # Round the numeric values in the column\n",
    "    df_q[column] = df_q[column].round(1)\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df_q.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a new column named 'q' as the first column\n",
    "df_q.insert(0, 'q', '')\n",
    "\n",
    "# Iterate through the DataFrame to find rows that start with 'Q'\n",
    "for index, row in df_q.iterrows():\n",
    "    if row['Răspunsuri'].startswith('Q'):\n",
    "        # Copy the value in the corresponding row to the 'q' column\n",
    "        df_q.at[index, 'q'] = row['Răspunsuri']\n",
    "\n",
    "# Forward fill values in the 'q' column\n",
    "df_q['q'] = df_q['q'].replace('', method='ffill')\n",
    "\n",
    "# Drop rows where 'question' column starts with 'Q'\n",
    "df_q = df_q[~df_q['Răspunsuri'].str.startswith('Q')]\n",
    "\n",
    "# Reset the index after dropping rows\n",
    "df_q = df_q.reset_index(drop=True)\n",
    "\n",
    "# Assuming df_q is your DataFrame\n",
    "# Create a new DataFrame to store the results\n",
    "df_q_result = pd.DataFrame(columns=df_q.columns)\n",
    "\n",
    "# Iterate through each unique question in the 'q' column\n",
    "for question in df_q['q'].unique():\n",
    "    # Filter the DataFrame for the current question\n",
    "    df_subset = df_q[df_q['q'] == question]\n",
    "\n",
    "    # Calculate the total for each column and insert it as a new row\n",
    "    total_row = df_subset.sum(axis=0)\n",
    "    total_row['Răspunsuri'] = \"Total\"\n",
    "\n",
    "    # Append the total row to the result DataFrame\n",
    "    df_q_result = pd.concat([df_q_result, df_subset, pd.DataFrame([total_row])], ignore_index=True)\n",
    "\n",
    "# Reset the index of the result DataFrame\n",
    "df_q_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert 'Total' and 'Relative Frequency' columns to numeric\n",
    "df_q['N'] = pd.to_numeric(df_q['N'], errors='coerce')\n",
    "df_q['Total'] = pd.to_numeric(df_q['Total'], errors='coerce')\n",
    "\n",
    "\n",
    "def adjust_total_column(df, target_sum=100):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    adjusted_df = df.copy()\n",
    "\n",
    "    # Identify the index of the 'Total' column\n",
    "    total_column_index = adjusted_df.columns.get_loc('Total')\n",
    "\n",
    "    # Iterate through all columns including 'Total'\n",
    "    for column_index in range(total_column_index, len(adjusted_df.columns)):\n",
    "        column_name = adjusted_df.columns[column_index]\n",
    "\n",
    "        # Dictionary to track whether the adjustment has been applied for each question\n",
    "        adjusted_dict = {}\n",
    "\n",
    "        # Iterate through the unique questions\n",
    "        for q in adjusted_df['q'].unique():\n",
    "            # Fill NaN values with 0 for the current column and question\n",
    "            adjusted_df[column_name].fillna(0, inplace=True)\n",
    "\n",
    "            # Filter rows for the current question\n",
    "            q_rows = adjusted_df[adjusted_df['q'] == q]\n",
    "\n",
    "            # Identify the maximum value in the current column for the current question\n",
    "            max_value = q_rows[column_name].max()\n",
    "\n",
    "            # Check if the maximum value has already been adjusted for the current question\n",
    "            if (q, column_name) not in adjusted_dict:\n",
    "                # Calculate the sum for the current column and question\n",
    "                current_sum = q_rows[column_name].sum()\n",
    "\n",
    "                # Check if the sum is non-zero before making adjustments\n",
    "                if current_sum != 0:\n",
    "                    # Calculate the difference from the target sum\n",
    "                    difference = target_sum - current_sum\n",
    "\n",
    "                    # Adjust the maximum value based on whether the sum was less or more than the target sum\n",
    "                    adjusted_df.loc[q_rows[column_name].idxmax(), column_name] += difference\n",
    "\n",
    "                    # Mark that adjustment has been applied for this question and column\n",
    "                    adjusted_dict[(q, column_name)] = True\n",
    "\n",
    "    return adjusted_df\n",
    "\n",
    "# Call the function to adjust only the first identified max value in each column to the right of and including 'Total'\n",
    "df_q = adjust_total_column(df_q)\n",
    "\n",
    "\n",
    "# SORTARE CU NU STIU/NU RASPUND\n",
    "# Function to sort each group by 'Relative Frequency' in descending order placing 'Nu ştiu' and 'Nu răspund' at the bottom\n",
    "\n",
    "def sort_within_group(group):\n",
    "    non_nu_values = group.loc[group['Răspunsuri'].ne('Nu ştiu') & group['Răspunsuri'].ne('Nu răspund') & group['Răspunsuri'].ne('Total')]\n",
    "    nu_values = group.loc[group['Răspunsuri'].isin(['Nu ştiu', 'Nu răspund', 'Total'])]\n",
    "\n",
    "    non_nu_values['rank'] = non_nu_values['Total'].rank(ascending=False)\n",
    "    non_nu_values.sort_values(by='rank', inplace=True)\n",
    "\n",
    "    sorted_group = pd.concat([non_nu_values, nu_values])\n",
    "    return sorted_group.drop(columns='rank')\n",
    "\n",
    "# Apply the sorting function within each group\n",
    "df_q_sorted = df_q.groupby('q', group_keys=False).apply(sort_within_group).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T_Q tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESAREA INTREBARILOR IN FORMAT T_Q\n",
    "\n",
    "# Assuming df_t is your DataFrame\n",
    "# Drop rows where 'question' is NaN\n",
    "df_t = df_t.dropna(subset=['Răspunsuri'])\n",
    "\n",
    "# Identify the rows where a new question starts, making the search case-insensitive and stripping any whitespace\n",
    "question_indices_t = df_t[df_t['Răspunsuri'].str.strip().str.startswith('T_Q')].index\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through each question section_t\n",
    "for i in range(len(question_indices_t) - 1):\n",
    "    start_idx_t = question_indices_t[i]\n",
    "    end_idx_t = question_indices_t[i + 1]\n",
    "\n",
    "    # Extract the relevant section_t of the DataFrame\n",
    "    section_t = df_t.loc[start_idx_t+1:end_idx_t]\n",
    "\n",
    "    # Convert columns to numeric (excluding the first 3 columns)\n",
    "    section_t.iloc[:, 3:] = section_t.iloc[:, 3:].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Calculate the sum of each column in the section_t (excluding the first 3 columns)\n",
    "    col_sums = section_t.iloc[:, 3:].sum(axis=0)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    col_sums_nonzero = col_sums.replace(0, 1)  # Replace zeros with 1 to avoid division by zero\n",
    "    section_t.iloc[:, 3:] = section_t.iloc[:, 3:].div(col_sums_nonzero, axis=1) * 100\n",
    "\n",
    "    # Replace NaN values with 0 after division\n",
    "    section_t.iloc[:, 3:].fillna(0, inplace=True)\n",
    "\n",
    "    # Update the original DataFrame with the calculated values\n",
    "    df_t.loc[start_idx_t+1:end_idx_t] = section_t\n",
    "\n",
    "# Corrected process for the last section\n",
    "start_idx_t = question_indices_t[-1]  # Use the correct list for indices\n",
    "section_t = df_t.loc[start_idx_t+1:]\n",
    "\n",
    "# Repeat the normalization steps for the last section\n",
    "section_t.iloc[:, 3:] = section_t.iloc[:, 3:].apply(pd.to_numeric, errors='coerce')\n",
    "col_sums = section_t.iloc[:, 3:].sum(axis=0)\n",
    "col_sums_nonzero = col_sums.replace(0, np.nan)  # Consider using NaN instead of replacing with 1\n",
    "section_t.iloc[:, 3:] = section_t.iloc[:, 3:].div(col_sums_nonzero, axis=1).multiply(100)\n",
    "section_t.iloc[:, 3:].fillna(0, inplace=True)\n",
    "df_t.loc[start_idx_t+1:] = section_t\n",
    "\n",
    "# Assuming df_t is your DataFrame\n",
    "# Find the index of the \"Relative Frequency\" column\n",
    "relative_frequency_index_t = df_t.columns.get_loc(\"Total\")\n",
    "\n",
    "# Select columns after the \"Relative Frequency\" column\n",
    "columns_to_round_t = df_t.columns[relative_frequency_index_t + 1:]\n",
    "\n",
    "# Iterate through the columns, convert to numeric, and round\n",
    "for column_t in columns_to_round_t:\n",
    "    # Try to convert the column to numeric\n",
    "    df_t[column_t] = pd.to_numeric(df_t[column_t], errors='coerce')\n",
    "\n",
    "    # Round the numeric values in the column\n",
    "    df_t[column_t] = df_t[column_t].round(1)\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df_t.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a new column named 'q' as the first column\n",
    "df_t.insert(0, 'q', '')\n",
    "\n",
    "# Iterate through the DataFrame to find rows that start with 'T_Q'\n",
    "for index_t, row_t in df_t.iterrows():\n",
    "    if row_t['Răspunsuri'].startswith('T_Q'):\n",
    "        # Copy the value in the corresponding row to the 'q' column\n",
    "        df_t.at[index_t, 'q'] = row_t['Răspunsuri']\n",
    "\n",
    "# Forward fill values in the 'q' column\n",
    "df_t['q'] = df_t['q'].replace('', method='ffill')\n",
    "\n",
    "# Drop rows where 'question' column starts with 'T_Q'\n",
    "df_t = df_t[~df_t['Răspunsuri'].str.startswith('T_Q')]\n",
    "\n",
    "# Reset the index after dropping rows\n",
    "df_t = df_t.reset_index(drop=True)\n",
    "\n",
    "# Assuming df_t is your DataFrame\n",
    "# Create a new DataFrame to store the results\n",
    "df_t_result = pd.DataFrame(columns=df_t.columns)\n",
    "\n",
    "# Iterate through each unique question in the 'q' column\n",
    "for question_t in df_t['q'].unique():\n",
    "    # Filter the DataFrame for the current question\n",
    "    df_subset_t = df_t[df_t['q'] == question_t]\n",
    "\n",
    "    # Calculate the total for each column and insert it as a new row\n",
    "    total_row_t = df_subset_t.sum(axis=0)\n",
    "    total_row_t['Răspunsuri'] = \"Total\"\n",
    "\n",
    "    # Append the total row to the result DataFrame\n",
    "    df_t_result = pd.concat([df_t_result, df_subset_t, pd.DataFrame([total_row_t])], ignore_index=True)\n",
    "\n",
    "# Reset the index of the result DataFrame\n",
    "df_t_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert 'Total' and 'Relative Frequency' columns to numeric\n",
    "df_t['N'] = pd.to_numeric(df_t['N'], errors='coerce')\n",
    "df_t['Total'] = pd.to_numeric(df_t['Total'], errors='coerce')\n",
    "\n",
    "# Call the function to adjust all columns to the right of 'Relative Frequency'\n",
    "df_t = adjust_total_column(df_t)\n",
    "\n",
    "# SORTARE CU NU STIU/NU RASPUND\n",
    "# Function to sort each group by 'Relative Frequency' in descending order placing 'Nu ştiu' and 'Nu răspund' at the bottom\n",
    "\n",
    "# Apply the sorting function within each group for df_t\n",
    "df_t_sorted = df_t.groupby('q', group_keys=False).apply(sort_within_group).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q_option tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PROCESAREA INTREBARILOR CU ALEGERI MULTIPLE Q_O_\n",
    "\n",
    "def adjust_total_column_multiple(df, target_sum=100):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    adjusted_df = df.copy()\n",
    "\n",
    "    # Fill NaN values with 0 for the 'Total' column\n",
    "    adjusted_df['Total'].fillna(0, inplace=True)\n",
    "\n",
    "    # Iterate through the unique questions\n",
    "    for q in adjusted_df['q'].unique():\n",
    "        # Filter rows for the current question\n",
    "        q_rows = adjusted_df[adjusted_df['q'] == q]\n",
    "\n",
    "        # Calculate the sum for the 'Total' column for the current question\n",
    "        current_sum = q_rows['Total'].sum()\n",
    "\n",
    "        # Check if the sum is non-zero before making adjustments\n",
    "        if current_sum != 0:\n",
    "            # Calculate the difference from the target sum\n",
    "            difference = target_sum - current_sum\n",
    "\n",
    "            # Adjust the maximum value based on whether the sum was less or more than the target sum\n",
    "            adjusted_df.loc[q_rows['Total'].idxmax(), 'Total'] += difference\n",
    "\n",
    "    return adjusted_df\n",
    "\n",
    "# Use apply to call the function only for the 'Relative Frequency' column\n",
    "results_multiple = adjust_total_column_multiple(results_multiple)\n",
    "\n",
    "\n",
    "# Apply the sorting function within each group\n",
    "rm_sorted = results_multiple.groupby('q', group_keys=False).apply(sort_within_group).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Tables Formating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dissagregation columns order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your specific order for age groups\n",
    "specific_order_age = ['18-29', '30-37', '38-47', '48-57', '58-66', '67+']\n",
    "\n",
    "# Define your specific order for regions\n",
    "specific_order_region = ['Nord', 'Centru', 'Mun. Chișinău', 'Sud', 'Găgăuzia']\n",
    "\n",
    "specific_order_m = ['Oraș','Sat','Necunoscut']\n",
    "\n",
    "specific_order_cat_sua = ['Russian speakers 15-29 years.','Russian speakers 30-39 years.','Romanian speakers 15-29 years.']\n",
    "\n",
    "# Define unique_values_list based on unique values in disaggregation columns\n",
    "unique_values_list = []\n",
    "for col in disaggregation_columns:\n",
    "    for item in df_dummies[col].unique():\n",
    "        if item not in unique_values_list:\n",
    "            unique_values_list.append(item)\n",
    "\n",
    "# Filter specific_order_age to include only those values that are present in unique_values_list\n",
    "filtered_specific_order_age = [item for item in specific_order_age if item in unique_values_list]\n",
    "\n",
    "# Filter specific_order_region to include only those values that are present in unique_values_list\n",
    "filtered_specific_order_region = [item for item in specific_order_region if item in unique_values_list]\n",
    "\n",
    "# Filter specific_order_m to include only those values that are present in unique_values_list\n",
    "filtered_specific_order_m = [item for item in specific_order_m if item in unique_values_list]\n",
    "\n",
    "# Filter specific_order_cat_sua to include only those values that are present in unique_values_list\n",
    "filtered_specific_order_cat_sua = [item for item in specific_order_cat_sua if item in unique_values_list]\n",
    "\n",
    "\n",
    "# Combine the filtered specific orders\n",
    "combined_filtered_specific_order = filtered_specific_order_age + filtered_specific_order_region + filtered_specific_order_m + specific_order_cat_sua\n",
    "\n",
    "# Now, place the values in combined_filtered_specific_order at the beginning of unique_values_list in the specified order\n",
    "# And include other items not in combined_filtered_specific_order\n",
    "unique_values_list = combined_filtered_specific_order + [item for item in unique_values_list if item not in combined_filtered_specific_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q_digit tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# FORMATAREA INTREBARILOR Q_DIGIT\n",
    "\n",
    "# Identify numeric columns (excluding non-numeric columns)\n",
    "numeric_columns = df_q_sorted.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Convert 'N' and 'Total' columns to numeric\n",
    "df_q_sorted['N'] = pd.to_numeric(df_q_sorted['N'], errors='coerce')\n",
    "df_q_sorted['Total'] = pd.to_numeric(df_q_sorted['Total'], errors='coerce')\n",
    "\n",
    "# Create a 'Total' row for each unique question\n",
    "totals = df_q_sorted.groupby('q')[numeric_columns].sum().reset_index()\n",
    "totals['Răspunsuri'] = 'Total'\n",
    "\n",
    "\n",
    "# Identify the unique questions\n",
    "unique_questions = df_q_sorted['q'].unique()\n",
    "\n",
    "# Initialize an empty DataFrame to store the result\n",
    "result_df_q = pd.DataFrame(columns=df_q.columns)\n",
    "\n",
    "# Iterate through unique questions and insert the 'N' row after each group\n",
    "for q in unique_questions:\n",
    "    question_rows = df_q[df_q['q'] == q]\n",
    "    result_df_q = pd.concat([result_df_q, question_rows, totals[totals['q'] == q]], ignore_index=True)\n",
    "\n",
    "def add_empty_rows_and_copy_labels(df):\n",
    "    # Create a mask to identify the unique question labels\n",
    "    mask = df['q'] != df['q'].shift(1)\n",
    "\n",
    "    # Define a function to add three empty rows for each group\n",
    "    def add_empty_rows_and_copy_labels_func(group):\n",
    "        empty_rows = pd.DataFrame(columns=df.columns, data=[[None] * len(df.columns)] * 3)\n",
    "\n",
    "        # Insert the label of the unique question group in the 'question' column of the second empty row\n",
    "        empty_rows.at[1, 'Răspunsuri'] = group['q'].iloc[1]\n",
    "\n",
    "        # Copy the column names and insert them above each group\n",
    "        empty_rows.iloc[[0, 2], :] = df.columns\n",
    "\n",
    "        return pd.concat([empty_rows, group.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "    # Apply the function to each group of unique questions\n",
    "    result_df = df.groupby('q').apply(add_empty_rows_and_copy_labels_func).reset_index(drop=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "result_df_q= result_df_q.groupby('q', group_keys=False).apply(sort_within_group).reset_index(drop=True)\n",
    "\n",
    "# Example usage:\n",
    "result_df_q = add_empty_rows_and_copy_labels(result_df_q)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the starting index for the replacement\n",
    "start_index = 1\n",
    "\n",
    "# Iterate through the 'q' column and replace entire rows for every second 'q' value starting from the specified index\n",
    "replace_count = 0\n",
    "for index, value in result_df_q['q'].items():\n",
    "    if index >= start_index and value == 'q':\n",
    "        if replace_count % 2 == 1:\n",
    "            result_df_q.iloc[index, :] = [None] * len(result_df_q.columns)\n",
    "        replace_count += 1\n",
    "\n",
    "# Cut the 'Total' column\n",
    "relative_frequency_col = result_df_q.pop('Total')\n",
    "\n",
    "# Insert the 'Total' column just after the 'N' column\n",
    "result_df_q.insert(result_df_q.columns.get_loc('N') + 1, 'Total', relative_frequency_col)\n",
    "\n",
    "\n",
    "# Create an empty DataFrame to store the result\n",
    "result_df_q_m = pd.DataFrame(columns=result_df_q.columns)\n",
    "\n",
    "\n",
    "# Iterate through the original DataFrame\n",
    "for index, row in result_df_q.iterrows():\n",
    "    # If the current row's question starts with 'Q_', insert an empty row above\n",
    "    if row['Răspunsuri'] is not None and row['Răspunsuri'].startswith('Q_'):\n",
    "        result_df_q_m = result_df_q_m.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "    # Append the current row to the result DataFrame\n",
    "    result_df_q_m = result_df_q_m.append(row)\n",
    "\n",
    "    # If the current row's question starts with 'Q_', insert an empty row below\n",
    "    if row['Răspunsuri'] is not None and row['Răspunsuri'].startswith('Q_'):\n",
    "        result_df_q_m = result_df_q_m.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "# Reset the index of the result DataFrame\n",
    "result_df_q_m.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Assuming 'Total' is the column after which you want to reorder\n",
    "total_column_index = result_df_q_m.columns.get_loc('Total')\n",
    "\n",
    "# Separate the DataFrame into three parts: before 'Total', 'Total', and after 'Total'\n",
    "columns_before_total = result_df_q_m.columns[:total_column_index]\n",
    "total_column = result_df_q_m.columns[total_column_index:total_column_index + 1]\n",
    "columns_after_total = result_df_q_m.columns[total_column_index + 1:]\n",
    "\n",
    "# Reorder the columns after 'Total' based on unique_values_list\n",
    "# Only include columns that are present in the DataFrame\n",
    "reordered_columns_after_total = [col for col in unique_values_list if col in columns_after_total]\n",
    "\n",
    "# Combine the columns back into the new order\n",
    "new_column_order = list(columns_before_total) + list(total_column) + reordered_columns_after_total\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "result_df_q_m = result_df_q_m[new_column_order]\n",
    "\n",
    "\n",
    "\n",
    "# Create a new DataFrame with the same columns and an empty first row\n",
    "empty_row_df = pd.DataFrame(columns=result_df_q_m.columns, index=[0])\n",
    "\n",
    "# Update the first row of result_df_q_m with the empty values\n",
    "result_df_q_m.iloc[0] = empty_row_df.iloc[0]\n",
    "\n",
    "# # Prompt the user to input the value they want to insert\n",
    "# value_to_insert = input(\"Introduceti denumirea grupei de dezagregare: \")\n",
    "\n",
    "value_to_insert = 'Grupe de dezagregare (%)'\n",
    "\n",
    "# Assuming 'Total' is the column after which you want to insert the value\n",
    "column_name = 'Total'\n",
    "column_index = result_df_q_m.columns.get_loc(column_name)\n",
    "\n",
    "# Calculate the index for the column after 'Total'\n",
    "insert_column_index = column_index + 1\n",
    "\n",
    "# Check if the insert_column_index is within the DataFrame's column range\n",
    "if insert_column_index < len(result_df_q_m.columns):\n",
    "    empty_row_count = 0\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in result_df_q_m.iterrows():\n",
    "        if pd.isnull(row.iloc[insert_column_index]):\n",
    "            empty_row_count += 1\n",
    "            if empty_row_count == 4:\n",
    "                # Insert the value into the DataFrame at the specified column index\n",
    "                result_df_q_m.iat[index, insert_column_index] = value_to_insert\n",
    "                # break  # Stop after the first insertion\n",
    "        else:\n",
    "            # Reset the counter if a non-empty value is encountered\n",
    "            empty_row_count = 0\n",
    "\n",
    "# If the insert_column_index is not valid, this part of the script will do nothing\n",
    "\n",
    "\n",
    "\n",
    "result_df_q_m.drop('q', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ATRIBUIREA INTREBARILOR\n",
    "\n",
    "# Create a dictionary mapping Variable Name to Original Text\n",
    "mapping_dict = questions_filtered_df.set_index('q_index')['Text'].to_dict()\n",
    "\n",
    "# Define a function to replace values in the 'question' column\n",
    "def replace_question(value):\n",
    "    if isinstance(value, str):\n",
    "        match = re.match(r'Q_(\\d+)', value)\n",
    "        if match:\n",
    "            question_number = match.group(1)\n",
    "            return f'Întrebarea {question_number} : {mapping_dict.get(value, \"\")}'\n",
    "    return value\n",
    "\n",
    "\n",
    "\n",
    "# Apply the custom function to the 'question' column\n",
    "result_df_q_m['Răspunsuri'] = result_df_q_m['Răspunsuri'].apply(replace_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T_Q tabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMATAREA INTREBARILOR T_Q\n",
    "\n",
    "\n",
    "# Identify numeric columns (excluding non-numeric columns)\n",
    "numeric_columns_t = df_t_sorted.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Convert 'N' and 'Total' columns to numeric\n",
    "df_t_sorted['N'] = pd.to_numeric(df_t_sorted['N'], errors='coerce')\n",
    "df_t_sorted['Total'] = pd.to_numeric(df_t_sorted['Total'], errors='coerce')\n",
    "\n",
    "# Create a 'Total' row for each unique question\n",
    "totals_t = df_t_sorted.groupby('q')[numeric_columns_t].sum().reset_index()\n",
    "totals_t['Răspunsuri'] = 'Total'\n",
    "\n",
    "# Identify the unique questions\n",
    "unique_questions_t = df_t_sorted['q'].unique()\n",
    "\n",
    "\n",
    "# Initialize an empty DataFrame to store the result\n",
    "result_df_t = pd.DataFrame(columns=df_t.columns)\n",
    "\n",
    "# Iterate through unique questions and insert the 'Total' row after each group\n",
    "for q_t in unique_questions_t:\n",
    "    question_rows_t = df_t[df_t['q'] == q_t]\n",
    "    result_df_t = pd.concat([result_df_t, question_rows_t, totals_t[totals_t['q'] == q_t]], ignore_index=True)\n",
    "\n",
    "result_df_t = result_df_t.groupby('q', group_keys=False).apply(sort_within_group).reset_index(drop=True)\n",
    "\n",
    "# Example usage:\n",
    "result_df_t = add_empty_rows_and_copy_labels(result_df_t)\n",
    "\n",
    "# Specify the starting index for the replacement\n",
    "start_index_t = 1\n",
    "\n",
    "# Iterate through the 'q' column and replace entire rows for every second 'q' value starting from the specified index\n",
    "replace_count_t = 0\n",
    "for index_t, value_t in result_df_t['q'].items():\n",
    "    if index_t >= start_index_t and value_t == 'q':\n",
    "        if replace_count_t % 2 == 1:\n",
    "            result_df_t.iloc[index_t, :] = [None] * len(result_df_t.columns)\n",
    "        replace_count_t += 1\n",
    "\n",
    "# Cut the 'Total' column\n",
    "relative_frequency_col_t = result_df_t.pop('Total')\n",
    "\n",
    "# Insert the 'Total' column just after the 'N' column\n",
    "result_df_t.insert(result_df_t.columns.get_loc('N') + 1, 'Total', relative_frequency_col_t)\n",
    "\n",
    "# Create an empty DataFrame to store the result\n",
    "result_df_t_m = pd.DataFrame(columns=result_df_t.columns)\n",
    "\n",
    "# Iterate through the original DataFrame\n",
    "for index_t, row_t in result_df_t.iterrows():\n",
    "    # If the current row's question starts with 'T_Q', insert an empty row above\n",
    "    if row_t['Răspunsuri'] is not None and row_t['Răspunsuri'].startswith('T_Q'):\n",
    "        result_df_t_m = result_df_t_m.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "    # Append the current row to the result DataFrame\n",
    "    result_df_t_m = result_df_t_m.append(row_t)\n",
    "\n",
    "    # If the current row's question starts with 'T_Q', insert an empty row below\n",
    "    if row_t['Răspunsuri'] is not None and row_t['Răspunsuri'].startswith('T_Q'):\n",
    "        result_df_t_m = result_df_t_m.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "# Reset the index of the result DataFrame\n",
    "result_df_t_m.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Assuming 'Total' is the column after which you want to reorder\n",
    "total_column_index = result_df_t_m.columns.get_loc('Total')\n",
    "\n",
    "# Separate the DataFrame into three parts: before 'Total', 'Total', and after 'Total'\n",
    "columns_before_total = result_df_t_m.columns[:total_column_index]\n",
    "total_column = result_df_t_m.columns[total_column_index:total_column_index + 1]\n",
    "columns_after_total = result_df_t_m.columns[total_column_index + 1:]\n",
    "\n",
    "# Reorder the columns after 'Total' based on unique_values_list\n",
    "# Only include columns that are present in the DataFrame\n",
    "reordered_columns_after_total = [col for col in unique_values_list if col in columns_after_total]\n",
    "\n",
    "# Combine the columns back into the new order\n",
    "new_column_order = list(columns_before_total) + list(total_column) + reordered_columns_after_total\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "result_df_t_m = result_df_t_m[new_column_order]\n",
    "\n",
    "\n",
    "# Create a new DataFrame with the same columns and an empty first row\n",
    "empty_row_df_t = pd.DataFrame(columns=result_df_t_m.columns, index=[0])\n",
    "\n",
    "# Update the first row of result_df_t_m with the empty values\n",
    "result_df_t_m.iloc[0] = empty_row_df_t.iloc[0]\n",
    "\n",
    "value_to_insert_t = value_to_insert\n",
    "\n",
    "# Assuming 'Total' is the column after which you want to insert the value\n",
    "column_name = 'Total'\n",
    "column_index = result_df_t_m.columns.get_loc(column_name)\n",
    "\n",
    "# Calculate the index for the column after 'Total'\n",
    "insert_column_index = column_index + 1\n",
    "\n",
    "# Check if the insert_column_index is within the DataFrame's column range\n",
    "if insert_column_index < len(result_df_t_m.columns):\n",
    "    empty_row_count = 0\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in result_df_t_m.iterrows():\n",
    "        if pd.isnull(row.iloc[insert_column_index]):\n",
    "            empty_row_count += 1\n",
    "            if empty_row_count == 4:\n",
    "                # Insert the value into the DataFrame at the specified column index\n",
    "                result_df_t_m.iat[index, insert_column_index] = value_to_insert\n",
    "                #break  # Stop after the first insertion\n",
    "        else:\n",
    "            # Reset the counter if a non-empty value is encountered\n",
    "            empty_row_count = 0\n",
    "\n",
    "# If the insert_column_index is not valid, this part of the script will do nothing\n",
    "\n",
    "\n",
    "result_df_t_m.drop('q', axis=1, inplace=True)\n",
    "\n",
    "# Loop through the DataFrame\n",
    "for i in range(1, len(result_df_t_m)):\n",
    "    value = result_df_t_m.loc[i, 'Răspunsuri']\n",
    "    \n",
    "    # Check if the value is a string and starts with 'T_Q'\n",
    "    if isinstance(value, str) and value.startswith('T_Q'):\n",
    "        # Extract the required part of the string\n",
    "        extracted_value = '_'.join(value.split('_')[:3])\n",
    "        \n",
    "        # Assign the extracted value to the previous row\n",
    "        result_df_t_m.loc[i - 1, 'Răspunsuri'] = extracted_value\n",
    "\n",
    "# ATRIBUIREA INTREBARILOR\n",
    "\n",
    "# Create a dictionary mapping Variable Name to Original Text\n",
    "mapping_dict = questions_filtered_df.set_index('q_index')['Text'].to_dict()\n",
    "\n",
    "def replace_question(value, mapping_dict):\n",
    "    if isinstance(value, str):\n",
    "        # Pattern for 'T_Q_123_456'\n",
    "        match = re.match(r'T_Q_(\\d+)_(\\d+)', value)\n",
    "        if match:\n",
    "            question_number = match.group(1)\n",
    "            replacement = f'opțiunea : {mapping_dict.get(value, \"Unknown\")}'\n",
    "            return replacement\n",
    "\n",
    "        # Pattern for 'T_Q_123'\n",
    "        match = re.match(r'T_Q_(\\d+)', value)\n",
    "        if match:\n",
    "            question_number = match.group(1)\n",
    "            replacement = f'Întrebarea {question_number} : {mapping_dict.get(value, \"Unknown\")}'\n",
    "            return replacement\n",
    "\n",
    "    return value\n",
    "\n",
    "# Apply the custom function to the 'question' column\n",
    "result_df_t_m['Răspunsuri'] = result_df_t_m['Răspunsuri'].apply(lambda x: replace_question(x, mapping_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q_option tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMATAREA INTREBARILOR Q_Option\n",
    "\n",
    "\n",
    "# Identify numeric columns (excluding non-numeric columns)\n",
    "numeric_columns_rm = rm_sorted.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Convert 'N' and 'Total' columns to numeric\n",
    "rm_sorted['N'] = pd.to_numeric(rm_sorted['N'], errors='coerce')\n",
    "rm_sorted['Total'] = pd.to_numeric(rm_sorted['Total'], errors='coerce')\n",
    "\n",
    "\n",
    "# Create a 'Total' row for each unique question\n",
    "totals_rm = rm_sorted.groupby('q')[numeric_columns_rm].sum().reset_index()\n",
    "totals_rm['Răspunsuri'] = 'Total'\n",
    "\n",
    "# Identify the unique questions\n",
    "unique_questions_rm = rm_sorted['q'].unique()\n",
    "\n",
    "\n",
    "# Apply the sorting function within each group\n",
    "rm_sorted = results_multiple.groupby('q', group_keys=False).apply(sort_within_group).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Initialize an empty DataFrame to store the result\n",
    "result_rm = pd.DataFrame(columns=df_t.columns)\n",
    "\n",
    "# Iterate through unique questions and insert the 'Total' row after each group\n",
    "for q_rm in unique_questions_rm:\n",
    "    question_rows_rm = rm_sorted[rm_sorted['q'] == q_rm]\n",
    "    result_rm = pd.concat([result_rm, question_rows_rm, totals_rm[totals_rm['q'] == q_rm]], ignore_index=True)\n",
    "\n",
    "result_rm = result_rm.groupby('q', group_keys=False).apply(sort_within_group).reset_index(drop=True)\n",
    "\n",
    "# Example usage:\n",
    "result_rm = add_empty_rows_and_copy_labels(result_rm)\n",
    "\n",
    "start_index_rm = 1\n",
    "\n",
    "# Iterate through the 'q' column and replace entire rows for every second 'q' value starting from the specified index\n",
    "replace_count_rm = 0\n",
    "for index_rm, value_rm in result_rm['q'].items():\n",
    "    if index_rm >= start_index_rm and value_rm == 'q':\n",
    "        if replace_count_rm % 2 == 1:\n",
    "            result_rm.iloc[index_rm, :] = [None] * len(result_rm.columns)\n",
    "        replace_count_rm += 1\n",
    "\n",
    "\n",
    "# Create an empty DataFrame to store the result\n",
    "result_rm_m = pd.DataFrame(columns=result_rm.columns)\n",
    "\n",
    "# Iterate through the original DataFrame\n",
    "for index_rm, row_rm in result_rm.iterrows():\n",
    "    # If the current row's question starts with 'Q', insert an empty row above\n",
    "    if row_rm['Răspunsuri'] is not None and row_rm['Răspunsuri'].startswith('Q'):\n",
    "        result_rm_m = result_rm_m.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "    # Append the current row to the result DataFrame\n",
    "    result_rm_m = result_rm_m.append(row_rm)\n",
    "\n",
    "    # If the current row's question starts with 'T_Q', insert an empty row below\n",
    "    if row_rm['Răspunsuri'] is not None and row_rm['Răspunsuri'].startswith('Q'):\n",
    "        result_rm_m = result_rm_m.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "# Reset the index of the result DataFrame\n",
    "result_rm_m.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Assuming 'Total' is the column after which you want to reorder\n",
    "total_column_index = result_rm_m.columns.get_loc('Total')\n",
    "\n",
    "# Separate the DataFrame into three parts: before 'Total', 'Total', and after 'Total'\n",
    "columns_before_total = result_rm_m.columns[:total_column_index]\n",
    "total_column = result_rm_m.columns[total_column_index:total_column_index + 1]\n",
    "columns_after_total = result_rm_m.columns[total_column_index + 1:]\n",
    "\n",
    "# Reorder the columns after 'Total' based on unique_values_list\n",
    "# Only include columns that are present in the DataFrame\n",
    "reordered_columns_after_total = [col for col in unique_values_list if col in columns_after_total]\n",
    "\n",
    "# Combine the columns back into the new order\n",
    "new_column_order = list(columns_before_total) + list(total_column) + reordered_columns_after_total\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "result_rm_m = result_rm_m[new_column_order]\n",
    "\n",
    "\n",
    "\n",
    "# Create a new DataFrame with the same columns and an empty first row\n",
    "empty_row_rm = pd.DataFrame(columns=result_rm_m.columns, index=[0])\n",
    "\n",
    "# Update the first row of result_df_t_m with the empty values\n",
    "result_rm_m.iloc[0] = empty_row_rm.iloc[0]\n",
    "\n",
    "\n",
    "value_to_insert_rm = value_to_insert\n",
    "\n",
    "# Assuming 'Total' is the column after which you want to insert the value\n",
    "column_name = 'Total'\n",
    "column_index = result_rm_m.columns.get_loc(column_name)\n",
    "\n",
    "# Calculate the index for the column after 'Total'\n",
    "insert_column_index = column_index + 1\n",
    "\n",
    "# Check if the insert_column_index is within the DataFrame's column range\n",
    "if insert_column_index < len(result_rm_m.columns):\n",
    "    empty_row_count = 0\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in result_rm_m.iterrows():\n",
    "        if pd.isnull(row.iloc[insert_column_index]):\n",
    "            empty_row_count += 1\n",
    "            if empty_row_count == 4:\n",
    "                # Insert the value into the DataFrame at the specified column index\n",
    "                result_rm_m.iat[index, insert_column_index] = value_to_insert\n",
    "                #break  # Stop after the first insertion\n",
    "        else:\n",
    "            # Reset the counter if a non-empty value is encountered\n",
    "            empty_row_count = 0\n",
    "\n",
    "# If the insert_column_index is not valid, this part of the script will do nothing\n",
    "\n",
    "\n",
    "result_rm_m.drop('q', axis=1, inplace=True)\n",
    "\n",
    "# Assuming result_rm_m is your DataFrame and 'Răspunsuri' is the column you want to modify\n",
    "result_rm_m['Răspunsuri'] = result_rm_m['Răspunsuri'].apply(\n",
    "    lambda x: x[0] + '_' + x[1:] if isinstance(x, str) and x.startswith('Q') else x\n",
    ")\n",
    "\n",
    "# ATRIBUIREA INTREBARILOR\n",
    "\n",
    "mapping_dict = questions_filtered_df.set_index('q_index')['Text'].to_dict()\n",
    "\n",
    "\n",
    "def replace_question(value):\n",
    "    if isinstance(value, str):\n",
    "        match = re.match(r'Q_(\\d+)', value)\n",
    "        if match:\n",
    "            question_number = match.group(1)\n",
    "            replacement = f'Întrebarea {question_number} : {mapping_dict.get(value, \"\")}'\n",
    "            return replacement\n",
    "    return value\n",
    "\n",
    "result_rm_m['Răspunsuri'] = result_rm_m['Răspunsuri'].apply(replace_question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to identify sections\n",
    "def identify_sections(df, column_name):\n",
    "    sections = []\n",
    "    start = None\n",
    "    for i, row in df.iterrows():\n",
    "        if pd.isna(row[column_name]) and start is not None:\n",
    "            sections.append((start, i))\n",
    "            start = None\n",
    "        elif not pd.isna(row[column_name]) and start is None:\n",
    "            start = i\n",
    "    if start is not None:\n",
    "        sections.append((start, len(df)))\n",
    "    return sections\n",
    "\n",
    "def sort_section(df, start, end):\n",
    "    section = df.iloc[start:end].copy()\n",
    "\n",
    "    section['N_sort'] = pd.to_numeric(section['N'], errors='coerce')\n",
    "\n",
    "    def matches_pattern(x, patterns):\n",
    "        return any(re.search(pattern, str(x), re.IGNORECASE) for pattern in patterns)\n",
    "\n",
    "    top_rows = section['Răspunsuri'].apply(lambda x: matches_pattern(x, ['^Răspunsuri$']))\n",
    "\n",
    "    # Improved regex for 'Nu știu' to capture common variations\n",
    "    # The pattern covers: optional whitespace, optional diacritics, and slight misspellings\n",
    "    nu_stiu_pattern = r'Nu\\s*[șş]{1}tiu.*'\n",
    "    nu_raspund_pattern = r'Nu (vreau să )?răspund'\n",
    "    bottom_rows = section['Răspunsuri'].apply(lambda x: matches_pattern(x, ['Total', r'Alt\\w*', nu_stiu_pattern, nu_raspund_pattern]))\n",
    "\n",
    "\n",
    "    other_rows = ~top_rows & ~bottom_rows\n",
    "\n",
    "    sorted_section = section[other_rows].sort_values(by='N_sort', ascending=False, na_position='last')\n",
    "\n",
    "    final_section = pd.concat([section[top_rows], sorted_section, section[bottom_rows]])\n",
    "\n",
    "    final_section = final_section.drop(columns=['N_sort'])\n",
    "\n",
    "    if len(final_section) != len(section):\n",
    "        raise ValueError(\"Mismatch in section lengths after sorting.\")\n",
    "\n",
    "    df.iloc[start:end] = final_section.values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Identify sections in the DataFrame\n",
    "sections = identify_sections(result_df_q_m, 'Răspunsuri')\n",
    "\n",
    "# Sort each section\n",
    "for start, end in sections:\n",
    "    sort_section(result_df_q_m, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify sections\n",
    "def identify_sections(df, column_name):\n",
    "    sections = []\n",
    "    start = None\n",
    "    for i, row in df.iterrows():\n",
    "        if pd.isna(row[column_name]) and start is not None:\n",
    "            sections.append((start, i))\n",
    "            start = None\n",
    "        elif not pd.isna(row[column_name]) and start is None:\n",
    "            start = i\n",
    "    if start is not None:\n",
    "        sections.append((start, len(df)))\n",
    "    return sections\n",
    "\n",
    "def sort_section(df, start, end):\n",
    "    section = df.iloc[start:end].copy()\n",
    "\n",
    "    section['N_sort'] = pd.to_numeric(section['N'], errors='coerce')\n",
    "\n",
    "    def matches_pattern(x, patterns):\n",
    "        return any(re.search(pattern, str(x), re.IGNORECASE) for pattern in patterns)\n",
    "\n",
    "    top_rows = section['Răspunsuri'].apply(lambda x: matches_pattern(x, ['^Răspunsuri$']))\n",
    "\n",
    "    # Improved regex for 'Nu știu' to capture common variations\n",
    "    nu_stiu_pattern = r'Nu\\s*[șş]{1}tiu.*'\n",
    "    nu_raspund_pattern = r'Nu (vreau să )?răspund'\n",
    "    bottom_rows = section['Răspunsuri'].apply(lambda x: matches_pattern(x, ['Total', r'Alt\\w*', nu_stiu_pattern, nu_raspund_pattern]))\n",
    "\n",
    "\n",
    "    other_rows = ~top_rows & ~bottom_rows\n",
    "\n",
    "    sorted_section = section[other_rows].sort_values(by='N_sort', ascending=False, na_position='last')\n",
    "\n",
    "    final_section = pd.concat([section[top_rows], sorted_section, section[bottom_rows]])\n",
    "\n",
    "    final_section = final_section.drop(columns=['N_sort'])\n",
    "\n",
    "    if len(final_section) != len(section):\n",
    "        raise ValueError(\"Mismatch in section lengths after sorting.\")\n",
    "\n",
    "    df.iloc[start:end] = final_section.values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Identify sections in the DataFrame\n",
    "sections = identify_sections(result_rm_m, 'Răspunsuri')\n",
    "\n",
    "# Apply the sorting to result_rm_m\n",
    "for start, end in sections:\n",
    "    sort_section(result_rm_m, start, end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### T_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify sections\n",
    "def identify_sections(df, column_name):\n",
    "    sections = []\n",
    "    start = None\n",
    "    for i, row in df.iterrows():\n",
    "        if pd.isna(row[column_name]) and start is not None:\n",
    "            sections.append((start, i))\n",
    "            start = None\n",
    "        elif not pd.isna(row[column_name]) and start is None:\n",
    "            start = i\n",
    "    if start is not None:\n",
    "        sections.append((start, len(df)))\n",
    "    return sections\n",
    "\n",
    "def sort_section_t(df, start, end):\n",
    "    section = df.iloc[start:end].copy()\n",
    "\n",
    "    # Helper function to extract the numeric part from a string for sorting\n",
    "    def extract_numeric_part(s):\n",
    "        match = re.search(r'(\\d+)', s)\n",
    "        return int(match.group(1)) if match else float('inf')  # Using infinity for strings without a numeric part\n",
    "\n",
    "    # Identify the rows\n",
    "    top_rows = section['Răspunsuri'] == 'Răspunsuri'\n",
    "    numeric_rows = section['Răspunsuri'].str.contains(r'^\\d+', regex=True)\n",
    "    total_rows = section['Răspunsuri'] == 'Total'\n",
    "    nu_stiu_pattern = r'Nu\\s*[șş]{1}tiu.*'\n",
    "    nu_stiu_rows = section['Răspunsuri'].str.contains(nu_stiu_pattern, regex=True)\n",
    "    # 'Nu vreau sa răspund' and 'Nu răspund' should be considered the same\n",
    "    nu_raspund_pattern = r'Nu (vreau să )?răspund'\n",
    "    nu_raspund_rows = section['Răspunsuri'].str.contains(nu_raspund_pattern, regex=True)\n",
    "\n",
    "\n",
    "    # Sort the numeric rows based on the numeric part\n",
    "    section['Numeric_Part'] = section['Răspunsuri'].apply(extract_numeric_part)\n",
    "    sorted_numeric_rows = section[numeric_rows].sort_values(by='Numeric_Part')\n",
    "\n",
    "    # Combine the rows in the desired order\n",
    "    final_section = pd.concat([\n",
    "        section[top_rows],\n",
    "        sorted_numeric_rows,\n",
    "        section[~top_rows & ~numeric_rows & ~total_rows & ~nu_stiu_rows & ~nu_raspund_rows],\n",
    "        section[nu_raspund_rows],\n",
    "        section[nu_stiu_rows],\n",
    "        section[total_rows]\n",
    "    ])\n",
    "\n",
    "    final_section = final_section.drop(columns=['Numeric_Part'], errors='ignore')\n",
    "\n",
    "    if len(final_section) != len(section):\n",
    "        raise ValueError(\"Mismatch in section lengths after sorting.\")\n",
    "\n",
    "    df.iloc[start:end] = final_section.values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Identify sections in the DataFrame\n",
    "sections = identify_sections(result_df_t_m, 'Răspunsuri')\n",
    "\n",
    "# Apply the sorting to result_rm_m\n",
    "for start, end in sections:\n",
    "    sort_section_t(result_df_t_m, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel formating and export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q_digit tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Workbook\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "# Give a name to the sheet\n",
    "ws.title = \"Intrebari_Q\"\n",
    "\n",
    "# Keep track of the last formatted cell\n",
    "last_formatted_cell = None\n",
    "\n",
    "# Iterate through the 'question' column\n",
    "for index, value in enumerate(result_df_q_m['Răspunsuri']):\n",
    "    cell = ws.cell(row=index + 2, column=1, value=value)\n",
    "\n",
    "    # Check if value is None\n",
    "    if value is not None:\n",
    "        # Convert 'value' to a string if it's a float\n",
    "        if isinstance(value, float):\n",
    "            value = str(value)\n",
    "\n",
    "        # Set the font and size\n",
    "        cell.font = Font(name='Arial', size=10 if value.startswith('Întrebare') else 9, bold=True)\n",
    "\n",
    "        # Set the alignment\n",
    "        if value == 'Răspunsuri':\n",
    "            cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        elif value == 'Total':\n",
    "            cell.alignment = Alignment(horizontal='right', vertical='center')\n",
    "        else:\n",
    "            cell.alignment = Alignment(horizontal='left', vertical='center')\n",
    "\n",
    "        # Keep track of the last formatted cell\n",
    "        last_formatted_cell = cell\n",
    "\n",
    "for index, value in enumerate(result_df_q_m['Răspunsuri']):\n",
    "    if value == 'Răspunsuri' and index > 0:  # Check if it's not the first row\n",
    "        ws.merge_cells(start_row=index + 1, start_column=1, end_row=index + 2, end_column=1)\n",
    "        ws.cell(row=index + 1, column=1).value = 'Răspunsuri'  # Remove this line\n",
    "        ws.cell(row=index +1 , column=1).alignment = Alignment(horizontal='center', vertical='center')\n",
    "\n",
    "\n",
    "# Iterate through the 'N' column\n",
    "for index, value in enumerate(result_df_q_m['N']):\n",
    "    cell = ws.cell(row=index + 2, column=2, value=value)\n",
    "\n",
    "    # Set the font and alignment based on value\n",
    "    if value == 'N':\n",
    "        cell.font = Font(name='Arial', size=9, bold=True)\n",
    "        cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "    else:\n",
    "        cell.font = Font(name='Arial', size=9, bold=False)\n",
    "        cell.alignment = Alignment(horizontal='right', vertical='center')\n",
    "\n",
    "# Perform the merge after formatting the entire 'N' column\n",
    "for index, value in enumerate(result_df_q_m['N']):\n",
    "    if value == 'N' and index > 0:  # Check if it's not the first row\n",
    "        ws.merge_cells(start_row=index + 1, start_column=2, end_row=index + 2, end_column=2)\n",
    "        ws.cell(row=index + 1, column=2).value = 'N'  # Set the merged cell value to 'N'\n",
    "        ws.cell(row=index + 1, column=2).alignment = Alignment(horizontal='center', vertical='center')\n",
    "        # Set the font style to Arial, size to 9, and make it bold\n",
    "        font_style = Font(name='Arial', size=9, bold=True)\n",
    "        ws.cell(row=index + 1, column=2).font = font_style\n",
    "\n",
    "\n",
    "# Iterate through the 'Total' column\n",
    "for index, value in enumerate(result_df_q_m['Total']):\n",
    "    cell = ws.cell(row=index + 2, column=3, value=value)\n",
    "\n",
    "    # Set the font and alignment based on value\n",
    "    if value == 'Total':\n",
    "        cell.font = Font(name='Arial', size=9, bold=True)\n",
    "        cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "    else:\n",
    "        cell.font = Font(name='Arial', size=9, bold=False)\n",
    "        cell.alignment = Alignment(horizontal='right', vertical='center')\n",
    "        # Format the value to '100.0' if it's not the header row\n",
    "        cell.number_format = '0.0'\n",
    "\n",
    "# Perform the merge after formatting the entire 'Total' column\n",
    "for index, value in enumerate(result_df_q_m['Total']):\n",
    "    if value == 'Total' and index > 0:  # Check if it's not the first row\n",
    "        ws.merge_cells(start_row=index + 1, start_column=3, end_row=index + 2, end_column=3)\n",
    "        ws.cell(row=index + 1, column=3).value = 'Total (%)'  # Set the merged cell value to 'Total'\n",
    "        ws.cell(row=index + 1, column=3).alignment = Alignment(horizontal='center', vertical='center')\n",
    "        # Set the font style to Arial, size to 9, and make it bold\n",
    "        font_style = Font(name='Arial', size=9, bold=True)\n",
    "        ws.cell(row=index + 1, column=3).font = font_style\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through the unique values list only if it's not empty\n",
    "if unique_values_list:\n",
    "    for col_index, col_name in enumerate(unique_values_list):\n",
    "        # Check if col_name exists in the DataFrame columns\n",
    "        if col_name in result_df_q_m.columns:\n",
    "            # Iterate through the column\n",
    "            for index, value in enumerate(result_df_q_m[col_name]):\n",
    "                cell = ws.cell(row=index + 2, column=col_index + 4, value=value)\n",
    "\n",
    "                # Set the font and alignment based on value\n",
    "                cell.font = Font(name='Arial', size=9, bold=True if str(value) in unique_values_list else False)\n",
    "                cell.alignment = Alignment(horizontal='center' if str(value) in unique_values_list else 'right', vertical='center')\n",
    "                if str(value) not in unique_values_list:\n",
    "                    cell.number_format = '0.0'\n",
    "    # Find the column name corresponding to the first value in unique_values_list\n",
    "    target_column_name = unique_values_list[0]\n",
    "    # Check if unique_values_list is not empty and value_to_insert is in the target column\n",
    "    if unique_values_list and value_to_insert in result_df_q_m.get(target_column_name, []):\n",
    "        for index_to_merge in [i for i, value in enumerate(result_df_q_m[target_column_name]) if value == value_to_insert]:\n",
    "            for col_index, col_name in enumerate(unique_values_list):\n",
    "                if col_name == target_column_name:\n",
    "                    ws.merge_cells(start_row=index_to_merge + 2, start_column=col_index + 4, end_row=index_to_merge + 2, end_column=col_index + 4 + len(unique_values_list) - 1)\n",
    "                    cell_to_insert = ws.cell(row=index_to_merge + 2, column=col_index + 4)\n",
    "                    cell_to_insert.value = value_to_insert\n",
    "                    cell_to_insert.font = Font(name='Arial', size=9, bold=True)\n",
    "                    cell_to_insert.alignment = Alignment(horizontal='center', vertical='center')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_Q tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Workbook for the second sheet\n",
    "ws_t = wb.create_sheet(title='Intrebari_T_Q')\n",
    "\n",
    "# Keep track of the last formatted cell for result_df_t_m\n",
    "last_formatted_cell_t = None\n",
    "\n",
    "# Iterate through the 'Răspunsuri' column for result_df_t_m and format cells\n",
    "for index_t, value_t in enumerate(result_df_t_m['Răspunsuri']):\n",
    "    cell_t = ws_t.cell(row=index_t + 2, column=1, value=value_t)\n",
    "\n",
    "    # Check if value is None\n",
    "    if value_t is not None:\n",
    "        # Convert 'value' to a string if it's a float\n",
    "        if isinstance(value_t, float):\n",
    "            value_t = str(value_t)\n",
    "\n",
    "        # Set the font and size\n",
    "        cell_t.font = Font(name='Arial', size=10 if value_t.startswith('Întrebare') else 9, bold=True)\n",
    "\n",
    "        # Set the alignment\n",
    "        if value_t == 'Răspunsuri':\n",
    "            cell_t.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        elif value_t == 'Total':\n",
    "            cell_t.alignment = Alignment(horizontal='right', vertical='center')\n",
    "        else:\n",
    "            cell_t.alignment = Alignment(horizontal='left', vertical='center')\n",
    "\n",
    "        # Keep track of the last formatted cell\n",
    "        last_formatted_cell_t = cell_t\n",
    "\n",
    "# Now perform the merging in a separate iteration\n",
    "for index_t, value_t in enumerate(result_df_t_m['Răspunsuri']):\n",
    "    if value_t == 'Răspunsuri' and index_t > 0:\n",
    "        ws_t.merge_cells(start_row=index_t + 1, start_column=1, end_row=index_t + 2, end_column=1)\n",
    "        ws_t.cell(row=index_t + 1, column=1).value = 'Răspunsuri'  # Remove this line\n",
    "        ws_t.cell(row=index_t +1 , column=1).alignment = Alignment(horizontal='center', vertical='center')\n",
    "\n",
    "\n",
    "# Iterate through the 'N' column for result_df_t_m\n",
    "for index_t, value_t in enumerate(result_df_t_m['N']):\n",
    "    cell_t = ws_t.cell(row=index_t + 2, column=2, value=value_t)\n",
    "\n",
    "    # Set the font and alignment based on value\n",
    "    if value_t == 'N':\n",
    "        cell_t.font = Font(name='Arial', size=9, bold=True)\n",
    "        cell_t.alignment = Alignment(horizontal='center', vertical='center')\n",
    "    else:\n",
    "        cell_t.font = Font(name='Arial', size=9, bold=False)\n",
    "        cell_t.alignment = Alignment(horizontal='right', vertical='center')\n",
    "\n",
    "# Perform the merge after formatting the entire 'N' column for result_df_t_m\n",
    "for index_t, value_t in enumerate(result_df_t_m['N']):\n",
    "    if value_t == 'N' and index_t > 0:  # Check if it's not the first row\n",
    "        ws_t.merge_cells(start_row=index_t + 1, start_column=2, end_row=index_t + 2, end_column=2)\n",
    "        ws_t.cell(row=index_t + 1, column=2).value = 'N'  # Set the merged cell value to 'N'\n",
    "        ws_t.cell(row=index_t + 1, column=2).alignment = Alignment(horizontal='center', vertical='center')\n",
    "        # Set the font style to Arial, size to 9, and make it bold\n",
    "        font_style_t = Font(name='Arial', size=9, bold=True)\n",
    "        ws_t.cell(row=index_t + 1, column=2).font = font_style_t\n",
    "\n",
    "\n",
    "# Iterate through the 'Total' column for result_df_t_m\n",
    "for index_t, value_t in enumerate(result_df_t_m['Total']):\n",
    "    cell_t = ws_t.cell(row=index_t + 2, column=3, value=value_t)\n",
    "\n",
    "    # Set the font and alignment based on value\n",
    "    if value_t == 'Total':\n",
    "        cell_t.font = Font(name='Arial', size=9, bold=True)\n",
    "        cell_t.alignment = Alignment(horizontal='center', vertical='center')\n",
    "    else:\n",
    "        cell_t.font = Font(name='Arial', size=9, bold=False)\n",
    "        cell_t.alignment = Alignment(horizontal='right', vertical='center')\n",
    "        # Format the value to '100.0' if it's not the header row\n",
    "        cell_t.number_format = '0.0'\n",
    "\n",
    "# Perform the merge after formatting the entire 'Total' column for result_df_t_m\n",
    "for index_t, value_t in enumerate(result_df_t_m['Total']):\n",
    "    if value_t == 'Total' and index_t > 0:  # Check if it's not the first row\n",
    "        ws_t.merge_cells(start_row=index_t + 1, start_column=3, end_row=index_t + 2, end_column=3)\n",
    "        ws_t.cell(row=index_t + 1, column=3).value = 'Total (%)'  # Set the merged cell value to 'Total'\n",
    "        ws_t.cell(row=index_t + 1, column=3).alignment = Alignment(horizontal='center', vertical='center')\n",
    "        # Set the font style to Arial, size to 9, and make it bold\n",
    "        font_style_t = Font(name='Arial', size=9, bold=True)\n",
    "        ws_t.cell(row=index_t + 1, column=3).font = font_style_t\n",
    "\n",
    "\n",
    "# Iterate through the unique values list only if it's not empty\n",
    "if unique_values_list:\n",
    "    for col_index_t, col_name_t in enumerate(unique_values_list):\n",
    "        # Check if col_name exists in the DataFrame columns\n",
    "        if col_name_t in result_df_t_m.columns:\n",
    "            # Iterate through the column\n",
    "            for index_t, value_t in enumerate(result_df_t_m[col_name_t]):\n",
    "                cell_t = ws_t.cell(row=index_t + 2, column=col_index_t + 4, value=value_t)\n",
    "\n",
    "                # Set the font and alignment based on value\n",
    "                cell_t.font = Font(name='Arial', size=9, bold=True if str(value_t) in unique_values_list else False)\n",
    "                cell_t.alignment = Alignment(horizontal='center' if str(value_t) in unique_values_list else 'right', vertical='center')\n",
    "                if str(value_t) not in unique_values_list:\n",
    "                    cell_t.number_format = '0.0'\n",
    "    # Find the column name corresponding to the first value in unique_values_list\n",
    "    target_column_name_t = unique_values_list[0]\n",
    "    # Check if unique_values_list is not empty and if value_to_insert_t is in the target column\n",
    "    if unique_values_list and value_to_insert_t in result_df_t_m.get(target_column_name_t, []):\n",
    "        for index_to_merge_t in [i for i, value_t in enumerate(result_df_t_m[target_column_name_t]) if value_t == value_to_insert_t]:\n",
    "            for col_index_t, col_name_t in enumerate(unique_values_list):\n",
    "                if col_name_t == target_column_name_t:\n",
    "                    ws_t.merge_cells(start_row=index_to_merge_t + 2, start_column=col_index_t + 4, end_row=index_to_merge_t + 2, end_column=col_index_t + 4 + len(unique_values_list) - 1)\n",
    "                    cell_to_insert_t = ws_t.cell(row=index_to_merge_t + 2, column=col_index_t + 4)\n",
    "                    cell_to_insert_t.value = value_to_insert_t\n",
    "                    cell_to_insert_t.font = Font(name='Arial', size=9, bold=True)\n",
    "                    cell_to_insert_t.alignment = Alignment(horizontal='center', vertical='center')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q_option tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Workbook for the second sheet\n",
    "ws_rm = wb.create_sheet(title='Intrebari_Q_multiple')\n",
    "\n",
    "# Keep track of the last formatted cell for result_rm_m\n",
    "last_formatted_cell_rm = None\n",
    "\n",
    "# Iterate through the 'question' column for result_rm_m\n",
    "for index_rm, value_rm in enumerate(result_rm_m['Răspunsuri']):\n",
    "    cell_rm = ws_rm.cell(row=index_rm + 2, column=1, value=value_rm)\n",
    "\n",
    "    # Check if value is None\n",
    "    if value_rm is not None:\n",
    "        # Convert 'value' to a string if it's a float\n",
    "        if isinstance(value_rm, float):\n",
    "            value_rm = str(value_rm)\n",
    "\n",
    "        # Set the font and size\n",
    "        cell_rm.font = Font(name='Arial', size=10 if value_rm.startswith('Întrebare') else 9, bold=True)\n",
    "\n",
    "        # Set the alignment\n",
    "        if value_rm == 'Răspunsuri':\n",
    "            cell_rm.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        elif value_rm == 'Total':\n",
    "            cell_rm.alignment = Alignment(horizontal='right', vertical='center')\n",
    "        else:\n",
    "            cell_rm.alignment = Alignment(horizontal='left', vertical='center')\n",
    "\n",
    "        # Keep track of the last formatted cell\n",
    "        last_formatted_cell_rm = cell_rm\n",
    "\n",
    "for index_rm, value_rm in enumerate(result_rm_m['Răspunsuri']):\n",
    "    if value_rm == 'Răspunsuri' and index_rm > 0:  # Check if it's not the first row\n",
    "        ws_rm.merge_cells(start_row=index_rm + 1, start_column=1, end_row=index_rm + 2, end_column=1)\n",
    "        ws_rm.cell(row=index_rm + 1, column=1).value = 'Răspunsuri'  # Remove this line\n",
    "        ws_rm.cell(row=index_rm +1 , column=1).alignment = Alignment(horizontal='center', vertical='center')\n",
    "\n",
    "\n",
    "# Iterate through the 'N' column for result_rm_m\n",
    "for index_rm, value_rm in enumerate(result_rm_m['N']):\n",
    "    cell_rm = ws_rm.cell(row=index_rm + 2, column=2, value=value_rm)\n",
    "\n",
    "    # Set the font and alignment based on value\n",
    "    if value_rm == 'N':\n",
    "        cell_rm.font = Font(name='Arial', size=9, bold=True)\n",
    "        cell_rm.alignment = Alignment(horizontal='center', vertical='center')\n",
    "    else:\n",
    "        cell_rm.font = Font(name='Arial', size=9, bold=False)\n",
    "        cell_rm.alignment = Alignment(horizontal='right', vertical='center')\n",
    "\n",
    "# Perform the merge after formatting the entire 'N' column for result_rm_m\n",
    "for index_rm, value_rm in enumerate(result_rm_m['N']):\n",
    "    if value_rm == 'N' and index_rm > 0:  # Check if it's not the first row\n",
    "        ws_rm.merge_cells(start_row=index_rm + 1, start_column=2, end_row=index_rm + 2, end_column=2)\n",
    "        ws_rm.cell(row=index_rm + 1, column=2).value = 'N'  # Set the merged cell value to 'N'\n",
    "        ws_rm.cell(row=index_rm + 1, column=2).alignment = Alignment(horizontal='center', vertical='center')\n",
    "        # Set the font style to Arial, size to 9, and make it bold\n",
    "        font_style_t = Font(name='Arial', size=9, bold=True)\n",
    "        ws_rm.cell(row=index_rm + 1, column=2).font = font_style_t\n",
    "\n",
    "\n",
    "# Iterate through the 'Total' column for result_rm_m\n",
    "for index_rm, value_rm in enumerate(result_rm_m['Total']):\n",
    "    cell_rm = ws_rm.cell(row=index_rm + 2, column=3, value=value_rm)\n",
    "\n",
    "    # Set the font and alignment based on value\n",
    "    if value_rm == 'Total':\n",
    "        cell_rm.font = Font(name='Arial', size=9, bold=True)\n",
    "        cell_rm.alignment = Alignment(horizontal='center', vertical='center')\n",
    "    else:\n",
    "        cell_rm.font = Font(name='Arial', size=9, bold=False)\n",
    "        cell_rm.alignment = Alignment(horizontal='right', vertical='center')\n",
    "        # Format the value to '100.0' if it's not the header row\n",
    "        cell_rm.number_format = '0.0'\n",
    "\n",
    "# Perform the merge after formatting the entire 'Total' column for result_rm_m\n",
    "for index_rm, value_rm in enumerate(result_rm_m['Total']):\n",
    "    if value_rm == 'Total' and index_rm > 0:  # Check if it's not the first row\n",
    "        ws_rm.merge_cells(start_row=index_rm + 1, start_column=3, end_row=index_rm + 2, end_column=3)\n",
    "        ws_rm.cell(row=index_rm + 1, column=3).value = 'Total (%)'  # Set the merged cell value to 'Total'\n",
    "        ws_rm.cell(row=index_rm + 1, column=3).alignment = Alignment(horizontal='center', vertical='center')\n",
    "        # Set the font style to Arial, size to 9, and make it bold\n",
    "        font_style_t = Font(name='Arial', size=9, bold=True)\n",
    "        ws_rm.cell(row=index_rm + 1, column=3).font = font_style_t\n",
    "\n",
    "\n",
    "# Iterate through the unique values list only if it's not empty\n",
    "if unique_values_list:\n",
    "    for col_index_rm, col_name_rm in enumerate(unique_values_list):\n",
    "        # Check if col_name exists in the DataFrame columns\n",
    "        if col_name_rm in result_rm_m.columns:\n",
    "            # Iterate through the column\n",
    "            for index_rm, value_rm in enumerate(result_rm_m[col_name_rm]):\n",
    "                cell_rm = ws_rm.cell(row=index_rm + 2, column=col_index_rm + 4, value=value_rm)\n",
    "\n",
    "                # Set the font and alignment based on value\n",
    "                cell_rm.font = Font(name='Arial', size=9, bold=True if str(value_rm) in unique_values_list else False)\n",
    "                cell_rm.alignment = Alignment(horizontal='center' if str(value_rm) in unique_values_list else 'right', vertical='center')\n",
    "                if str(value_rm) not in unique_values_list:\n",
    "                    cell_rm.number_format = '0.0'\n",
    "    # Find the column name corresponding to the first value in unique_values_list\n",
    "    target_column_name_rm = unique_values_list[0]\n",
    "    # Check if unique_values_list is not empty and if value_to_insert_rm is in the target column\n",
    "    if unique_values_list and value_to_insert_rm in result_rm_m.get(target_column_name_rm, []):\n",
    "        for index_to_merge_rm in [i for i, value_rm in enumerate(result_rm_m[target_column_name_rm]) if value_rm == value_to_insert_rm]:\n",
    "            for col_index_rm, col_name_rm in enumerate(unique_values_list):\n",
    "                if col_name_rm == target_column_name_rm:\n",
    "                    ws_rm.merge_cells(start_row=index_to_merge_rm + 2, start_column=col_index_rm + 4, end_row=index_to_merge_rm + 2, end_column=col_index_rm + 4 + len(unique_values_list) - 1)\n",
    "                    cell_to_insert_rm = ws_rm.cell(row=index_to_merge_rm + 2, column=col_index_rm + 4)\n",
    "                    cell_to_insert_rm.value = value_to_insert_rm\n",
    "                    cell_to_insert_rm.font = Font(name='Arial', size=9, bold=True)\n",
    "                    cell_to_insert_rm.alignment = Alignment(horizontal='center', vertical='center')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base file name\n",
    "base_file_name = str(file_name)\n",
    "\n",
    "# Modify file name based on disaggregation_columns\n",
    "if not disaggregation_columns:\n",
    "    # If disaggregation_columns is empty, add 'Total' to the file name\n",
    "    base_file_name += '_Total'\n",
    "else:\n",
    "    # If disaggregation_columns is not empty, add 'Grupe de dezagragare' to the file name\n",
    "    base_file_name += '_Grupe_de_dezagragare'\n",
    "\n",
    "# Further modify file name based on apply_weights\n",
    "if apply_weights == 'y':\n",
    "    base_file_name += '_ponderat'\n",
    "\n",
    "# Add file extension\n",
    "file_name = base_file_name + '.xlsx'\n",
    "\n",
    "# Save the workbook with the modified file name\n",
    "wb.save(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test weights function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to convert all string characters in a DataFrame to UTF-8\n",
    "# def convert_to_utf8(df):\n",
    "#     for col in df.columns:\n",
    "#         if df[col].dtype == object:  # checks if the column is of type 'object' (typically for strings)\n",
    "#             df[col] = df[col].apply(lambda x: x.encode('utf-8').decode('utf-8') if isinstance(x, str) else x)\n",
    "#     return df\n",
    "\n",
    "# # Convert the DataFrame\n",
    "# converted_df = convert_to_utf8(df_q)\n",
    "# converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted_df.to_excel('dat.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def update_weights_for_combined_category(df, combined_categories, target_proportion, current_weights):\n",
    "#     # Check if current_weights is a Series and has the same length as df\n",
    "#     if not isinstance(current_weights, pd.Series) or len(current_weights) != len(df):\n",
    "#         raise ValueError(\"current_weights must be a pandas Series with the same length as df\")\n",
    "\n",
    "#     # Calculate the count for each category-value pair in combined_categories\n",
    "#     combined_sample_count = sum(df[df[category] == value].shape[0] for category, value in combined_categories)\n",
    "\n",
    "#     # Calculate combined sample proportion\n",
    "#     combined_sample_proportion = combined_sample_count / len(df)\n",
    "#     print(f\"Combined sample proportion: {combined_sample_proportion}\")\n",
    "\n",
    "#     # Avoid division by zero and ensure there's data for combined categories\n",
    "#     if combined_sample_proportion == 0:\n",
    "#         raise ValueError(\"No data for combined categories or zero proportion in data\")\n",
    "\n",
    "#     # # Calculate adjustment factor\n",
    "#     adjustment_factor = target_proportion / combined_sample_proportion\n",
    "#     print(f\"Adjustment factor: {adjustment_factor}\")\n",
    "\n",
    "#     # Create a copy of the current_weights to modify\n",
    "#     adjusted_weights = current_weights.copy()\n",
    "\n",
    "#     # Apply the adjustment factor to the weights of the matching rows\n",
    "#     for category, value in combined_categories:\n",
    "#         matching_rows = df[category] == value\n",
    "#         print(f\"Matching rows for category '{category}' and value '{value}':\\n{matching_rows}\")\n",
    "\n",
    "#         adjusted_weights[matching_rows] *= adjustment_factor\n",
    "#         print(f\"Adjusted weights after applying factor for '{category}-{value}':\\n{adjusted_weights}\")\n",
    "\n",
    "#     return adjusted_weights\n",
    "\n",
    "# # Define the function to update weights for combined categories\n",
    "# def update_weights_for_combined_category(df, combined_categories, target_proportion, current_weights):\n",
    "#     # Combine counts for similar categories\n",
    "#     combined_sample_count = sum(df[category].value_counts(dropna=False).get(value, 0)\n",
    "#                                 for category, value in combined_categories)\n",
    "\n",
    "#     # Calculate combined sample proportion\n",
    "#     combined_sample_proportion = combined_sample_count / len(df)\n",
    "\n",
    "#     # Calculate adjustment factor for the combined category\n",
    "#     adjustment_factor = (target_proportion / combined_sample_proportion \n",
    "#                          if combined_sample_proportion > 0 else 1)\n",
    "\n",
    "#     # Apply the adjustment factor to the weights of the matching rows\n",
    "#     for category, value in combined_categories:\n",
    "#         current_weights = current_weights.where(df[category] != value, \n",
    "#                                                 current_weights * adjustment_factor)\n",
    "\n",
    "#     return current_weights\n",
    "\n",
    "\n",
    "# def test_basic_functionality():\n",
    "#     # Create a sample DataFrame\n",
    "#     data = {'category': ['A', 'B', 'A', 'C'],\n",
    "#             'value': [1, 2, 3, 4]}\n",
    "#     df = pd.DataFrame(data)\n",
    "#     current_weights = pd.Series([1, 1, 1, 1], dtype='float64')  # Ensure current_weights is float64\n",
    "\n",
    "#     # Define test input\n",
    "#     combined_categories = [('category', 'A')]\n",
    "#     target_proportion = 0.75  # 75%\n",
    "\n",
    "#     # Call the function\n",
    "#     updated_weights = update_weights_for_combined_category(\n",
    "#         df, combined_categories, target_proportion, current_weights)\n",
    "\n",
    "#     # Ensure expected_weights is float64\n",
    "#     expected_weights = pd.Series([1.5, 1, 1.5, 1], dtype='float64')\n",
    "#     # Debugging: Print statements to check values\n",
    "#     print(\"Updated weights:\", updated_weights)\n",
    "#     print(\"Expected weights:\", expected_weights),      \n",
    "#     # Assert\n",
    "#     pd.testing.assert_series_equal(updated_weights, expected_weights)\n",
    "\n",
    "# # Call your test function\n",
    "# test_basic_functionality()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Now, let's plot the histogram of the 'Weight' column using the same style as the image provided\n",
    "# plt.figure(figsize=(10, 6))  # Set the size of the plot\n",
    "# plt.hist(df_modified['Weight'], bins=40, color='darkseagreen', edgecolor='black')  # Specify the number of bins and color\n",
    "\n",
    "# # Aesthetics for the plot to match the style of the provided image\n",
    "# plt.title('Distributia ponderilor', fontsize=10, fontweight='bold')\n",
    "# plt.xlabel('Pondere', fontsize=12)\n",
    "# plt.ylabel('Frecvență', fontsize=12)\n",
    "# plt.xticks(fontsize=10)\n",
    "# plt.yticks(fontsize=10)\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_modified['Weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test question selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selectam fisierul\n",
    "# filename = input(\"Introduceti denumirea fisierului care contine textul intrebarilor: \")\n",
    "# filename1 = f\"{filename}.xls\"\n",
    "\n",
    "# df_questions = pd.read_excel(filename1)\n",
    "\n",
    "# # Method 1: Using loc\n",
    "# df_filtered = df_questions.loc[df_questions['Is Topic'] != False]\n",
    "# # Dropping the first two rows of df_filtered\n",
    "# df_filtered = df_filtered.iloc[2:]\n",
    "# # Dropping rows where 'Question Index' column has NA/null values\n",
    "# df_filtered = df_filtered.dropna(subset=['Question Index'])\n",
    "# # Selecting only 'Question Index' and 'Text' columns\n",
    "# df_filtered = df_filtered[['Question Index', 'Text']]\n",
    "# # Replacing <b> and </b> with an empty string in the 'Text' column\n",
    "# df_filtered['Text'] = df_filtered['Text'].replace('<b>|</b>', '', regex=True)\n",
    "# # Extracting column names that start with \"Q\" and \"T_Q\"\n",
    "# filtered_columns = [col for col in df_original.columns if col.startswith('Q_') or col.startswith('T_Q')]\n",
    "\n",
    "# # Creating a new DataFrame with these column names as values in a single column\n",
    "# df_columns = pd.DataFrame({'column_names': filtered_columns})\n",
    "\n",
    "# # Create a new DataFrame for modified data with T_Q_digit part as the header of each section\n",
    "# df_columns_new = pd.DataFrame(columns=df_columns.columns)\n",
    "\n",
    "# # Initialize last_group as None to indicate no group has been encountered yet\n",
    "# last_group = None\n",
    "\n",
    "# for index, row in df_columns.iterrows():\n",
    "#     # Extract the group number from the 'T_Q' pattern\n",
    "#     match = re.match(r'T_Q_(\\d+)_\\d+', str(row['column_names']))\n",
    "#     if match:\n",
    "#         current_group = int(match.group(1))\n",
    "\n",
    "#         # Insert a row with the T_Q_digit part if it's the first group or if the group number changes\n",
    "#         if last_group is None or current_group != last_group:\n",
    "#             df_columns_new = df_columns_new.append(pd.Series({'column_names': f'T_Q_{current_group}'}), ignore_index=True)\n",
    "\n",
    "#         # Update the last seen group number\n",
    "#         last_group = current_group\n",
    "\n",
    "#     # Append the current row\n",
    "#     df_columns_new = df_columns_new.append(row)\n",
    "\n",
    "# # Reset index for the new DataFrame\n",
    "# df_columns_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# def filter_specific_pattern(dataframe, pattern_to_keep, general_pattern):\n",
    "#     # Function to check if the entry matches the general pattern and ends with the specific pattern\n",
    "#     def entry_matches(entry):\n",
    "#         return re.match(general_pattern, entry) and entry.endswith(pattern_to_keep)\n",
    "\n",
    "#     # Apply the filter to the DataFrame\n",
    "#     filtered_dataframe = dataframe[\n",
    "#         dataframe['column_names'].apply(lambda x: not re.match(general_pattern, x) or entry_matches(x))\n",
    "#     ]\n",
    "\n",
    "#     return filtered_dataframe\n",
    "\n",
    "# # The specific pattern we want to keep\n",
    "# specific_ending = '_O1'\n",
    "\n",
    "# # The general pattern that the questions must match (e.g., 'Q_number_Osomething')\n",
    "# question_pattern = r'Q_\\d+_O\\d+'\n",
    "\n",
    "# # Apply the filter function to the DataFrame\n",
    "# df_columns_new = filter_specific_pattern(df_columns_new, specific_ending, question_pattern)\n",
    "\n",
    "# # Step 1: Remove '_O1' from the end of strings in 'column_names'\n",
    "# df_columns_new['column_names'] = df_columns_new['column_names'].str.replace('_O1', '', regex=False)\n",
    "\n",
    "# # Step 2: Drop rows where 'column_names' ends with 'S'\n",
    "# df_columns_new = df_columns_new[~df_columns_new['column_names'].str.endswith('S')]\n",
    "\n",
    "# # Truncate df_filtered to match the length of df_columns_new\n",
    "# df_filtered = df_filtered.iloc[:len(df_columns_new)]\n",
    "\n",
    "# # Assign values from 'column_names' in df_columns_new to 'q_index' in df_filtered\n",
    "# df_filtered['q_index'] = df_columns_new['column_names'].values\n",
    "\n",
    "# # Reorder columns and drop 'Question index'\n",
    "# df_filtered = df_filtered[['q_index', 'Text']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Russian speakers 15-29 years.',\n",
       " 'Russian speakers 30-39 years.',\n",
       " 'Romanian speakers 15-29 years.']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
